{
    "componentChunkName": "component---themes-advanced-src-templates-post-query-ts",
    "path": "/ml-ops",
    "result": {"data":{"mdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"ML Ops\",\n  \"cover\": \"images/MLOps/MLOps.png\",\n  \"coverAlt\": \"Ml Ops\",\n  \"description\": \"Performing a Statistic tests\",\n  \"datePublished\": \"2022-06-05\",\n  \"dateModified\": \"2022-06-05\",\n  \"category\": \"Ops\",\n  \"tags\": [\"Machine Learning\", \"DevOps\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Introduction\"), mdx(\"p\", null, \"Traditional software application code is deterministic and always runs as written. When you deploy new code, hopefully, all the rigorous tests you've written, work and catch any bugs allowing the application to continue to work as expected. However, the world of machine learning is different. Machine learning models are dynamic and, thus, they degrade overtime after being deployed to production. They are sensitive to real changes to the world. A model is at it's best just before being deployed.\"), mdx(\"p\", null, \"There are two levels for monitoring a machine learning model in production: Functional Level monitoring and Operational Level monitoring.\"), mdx(\"p\", null, \"Functional monitoring involves monitoring the model performance, input, and output.\\nOperational monitoring involves monitoring at the system and resource levels.\"), mdx(\"img\", {\n    \"src\": \"images/MLOps/MLOps_Cycle.png\",\n    \"alt\": \"ML Ops Cycle\"\n  }), mdx(\"h2\", null, \"Functional monitoring\"), mdx(\"p\", null, \"This is typically the responsibility of the data scientist where we must monitor the input data, the prediction made by the model, and what goes inside the model while making that prediction during production (see my \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"./interpreting-ml-models-part-2\"\n  }, \"Model Interpreting\"), \" blog).\"), mdx(\"p\", null, \"There are many possible problems that can cause poor model predictions along the data pipeline. Although many of these processes requires input from the data scientist. We must ensure other teams are alerted so a holistic, longer term solution, can be deployed rather than a code patch from the data scientist.\"), mdx(\"h3\", null, \"Input Data\"), mdx(\"p\", null, \"Monitoring the input data ensures the model gets what the data scientist expected when the model was first trained. Any deviation from this will cause poor predictions (GIGO - garbage in garbage out) - which is why we need to ensure we monitor the data before it even passes into model.\"), mdx(\"p\", null, \"There are three cases you may want to monitor the input data:\"), mdx(\"h5\", null, \"1. Data Quality issues:\"), mdx(\"p\", null, \"Monitoring data properties we can ensure that a flag, or an alert, is triggered when the data is not what we expect so that the data team or service owner can take a look.\"), mdx(\"p\", null, \"These can also be caused by preprocessing steps within the data pipeline, changes in source data (e.g. data schema change, column renaming), or data loss/corruption.\"), mdx(\"p\", null, \"To name a few examples, we can write numerous tests to detect data quality issues:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Duplicates;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Missing values;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Syntax errors;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data type or format errors;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Schema changes;\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Data profiling;\")), mdx(\"p\", null, \"This list can go on and on for tabular datasets but also extends out to include visual, audio and video based data types.\"), mdx(\"h5\", null, \"2. Data Drift:\"), mdx(\"p\", null, \"Monitoring data drift is an important part of functional monitoring. We can understand ahead of time when the data is changing and retrain the model to the change in distribution between the training data and production data. This process typically happens over time. \"), mdx(\"p\", null, \"These changes are particularly common in features, thus, we must pay close attention to changes in individual features too.\"), mdx(\"p\", null, \"Descriptive statistics can be used: measure of central tendency,  measure of variability, measure of frequency and measure of position - read more at my blog post \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"./#12-StatsTests\"\n  }, \"here\"), \" and this \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"towardsdatascience\"), \" blog \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://towardsdatascience.com/using-statistical-distance-metrics-for-machine-learning-observability-4c874cded78\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"here\"), \". We would need to understand the domain and use relevant metrics to ensure the features do not degrade model performance. For example, these properties could include standard deviation, mean, mode, median and so on. \"), mdx(\"p\", null, \"To detect data drift we can introduce distribution tests into pipeline such as divergence, distance, or, categorical tests. The output of these tests can then form the foundation of measuring these changes, alert the service owner, start a retraining cycle, alert the data scientist to build a new model, or build a challenger model and then perform A/B testing against the deployed one.\"), mdx(\"h5\", null, \"3. Outliers:\"), mdx(\"p\", null, \"Outliers do not have a learnable structure across an entire dataset so will cause the model to return unreliable responses. It is one of the hardest data issues to detect, because extreme values can be a one off event and difficult to handle through rules.\"), mdx(\"p\", null, \"We can attempt to detect outliers by performing tests similiar to that of the data drift ones, create a supervised learning, or use autoML to detect outliers.\"), mdx(\"p\", null, \"The solutions may involve data slicing and analysing model performance on each subset of the data (i\", \".\", \"e\", \".\", \" cross validation folds), understand when the outlier occurs (by performing analysis) and introduce rules or human intervention to assist with the decision process for that period.\"), mdx(\"h3\", null, \"Model\"), mdx(\"p\", null, \"The input data is arguably one that could change the most. However, the model is the most important piece to monitor. \"), mdx(\"h5\", null, \"1. Monitoring Model drift\"), mdx(\"p\", null, \"Similar to data drift, model drift occurs when the relationship between the features and the target no longer holds due to changes over time. The model predictions become increasingly unreliable and less accurate over time, and no longer meet the benchmark, business metrics and KPIs set out.\"), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"768px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/2cefc/model_drift.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"56.25%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABRklEQVQoz51SiW7DIBTL//9gKnXV1KohS0I5WqDhep5yNT22VZoliwcYyw8oANDABUv909rDfOGTpsg5U0oJC6a9R9yv0WxFM580VBhjaLfboa5rGszfJVzS3TrTmsg5mk2pGEYhNS7GjDqiVw6oqgplWSKEMCWyFiQl0DSAc7Q4joZcKLje019tfTUNNmWJputASiFpheQ9riEgTp2tCflJ4qI05RjhtZ5M7+4w9j28c2P9sdlAfH4i5AylNRhjsNa+GvL9ga5tg/N+D1NVsHUNyxiuQsAwBnM8ImgNvt3CXS63TnLOyERPhkLBx7SGShGIAdn3SMNhykDO8EriF9DtlRfDw7Gmlks03QntSa4UCi0XIzuh0HAxakYdF2B1C6nOjwmH2L331HuPkf0bzhofIpQ+Q2tN871TQevvJPwf0we1lr4BN3JckXixXbIAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Model Drift Example due to COVID-19\",\n    \"title\": \"Model Drift Example due to COVID-19\",\n    \"src\": \"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/e5715/model_drift.png\",\n    \"srcSet\": [\"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/8514f/model_drift.png 192w\", \"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/804b2/model_drift.png 384w\", \"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/e5715/model_drift.png 768w\", \"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/4ad3a/model_drift.png 1152w\", \"/static/0cb5d5ef8b8323c74ed535495d1bd0b6/2cefc/model_drift.png 1400w\"],\n    \"sizes\": \"(max-width: 768px) 100vw, 768px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Model Drift Example due to COVID-19\"), \"\\n  \"), mdx(\"p\", null, \"There are several types of model drift:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Instantaneous model drift, a sudden drop in model performance caused by input data issues. An example of this is when COVID-19 lockdowns started, input data changed rapidly while predictions made by the model could not keep up. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Gradual model drift occurs when data changes over time as a result of external factors such as user behaviour changes, new features, or new demographics. \"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Recurring model drift is caused by seasonal events that occur periodically. For example, holidays, yearly discounts or customer spikes in regions.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Temporary model drift occurs during strange, one-off events. For example, the model temporarily drops in performance because of a spike in newer clients, system performance issues, or adversarial attacks before returning back to normal levels.\")), mdx(\"p\", null, \"To monitor model drift we can set the predictive metrics threshold and either perform hyperparameter optimisation, retrain the model, send an alert when we need to analyze the model for degradations or drifts, or, more challengingly, use online learning algorithms.\"), mdx(\"h5\", null, \"2. Model Configuration and Artifacts\"), mdx(\"p\", null, \"Just like any other report or business document, we need to keep track of all configurations related to our model. This can aid in replication and help use replicate our work for others. The configuration file contains model information, version, author, hyperparameters, dependencies, features values and more. This can help us understand when things started going wrong and why.\"), mdx(\"p\", null, \"Tying the configuration with the deployed model version is a great way of ensuring the right model is deployed.\"), mdx(\"h5\", null, \"3. Concerted adversaries\"), mdx(\"p\", null, \"Machine learning models are susceptible to adversarial attacks. They vigorously attack your system/model so it makes a mistake. To monitor these sort of attacks we need to flag inputs with outlier events, it is common for adversarial attacks to be atypical events. Another possibility is adding human intervention to the pipeline whenever a marginally detected anomalous event occurs within the input data. We could also add business logic to the pipeline and modelling so that subject expert knowledge on adversarial attacks can be incorporated. \"), mdx(\"h3\", null, \"Predictions\"), mdx(\"p\", null, \"Monitoring the predictions that the model outputs can provide many useful insights and allow us to compare it to business KPIs.\"), mdx(\"h5\", null, \"1. Model evaluation metrics\"), mdx(\"p\", null, \"Different machine learning problems require the use of different metrics such as regression, classification, clustering, reinforcement learning, computer vision and so on. We should monitor metrics most relevant to the machine learning problem that we are trying to solve and the business KPIs.\"), mdx(\"p\", null, \"As you probably already know, metrics for a classification model include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Accuracy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Confusion Matrix,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"ROC-AUC Score,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Precision and Recall Scores,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"F1-Score.\")), mdx(\"p\", null, \"Metrics for a regression model include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Root Mean Square Error (RMSE),\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"R-Squared, Adjusted R-Squared and Normalized R-Squared Metrics,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Mean Absolute Error (MAE),\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Mean Absolute Percentage Error (MAPE).\")), mdx(\"h5\", null, \"2. Truth Labels\"), mdx(\"p\", null, \"It is sometimes unclear whether true labels will be present when predictions have been made, or, real time model metrics are even possible at all and a delayed metric is reported instead. Comparing actual labels to predictions in production is a very difficult task in most cases.\"), mdx(\"p\", null, \"When true labels are not available we can catch monitor the prediction distribution as this should have been set to the business KPI.\"), mdx(\"h2\", null, \"Operational level monitoring\"), mdx(\"p\", null, \"The system monitoring and operation typically falls under the responsibility of the IT operations team but this has to be a shared responsibility when it comes to machine learning and deployment of models. Data scientist should be responsible for monitoring model performance and data coming into the model. \"), mdx(\"h4\", null, \"System performance monitoring\"), mdx(\"p\", null, \"This is primarily an infrastructure problem. We need to make sure that the application's latency, uptime, scalability, adaptability, extensibility etc are monitored and metrics are being tracked. Understanding these key metrics can help data scientists if their model has high latency in returning predictions, which may have affected the overall application's speed.\"), mdx(\"p\", null, \"The metrics that may be worth monitoring include, but not limited to: CPU/GPU utilization, memory utilization, failed requests, API calls, and response time. This may not be the direct responsibility but it's extremely helpful to be aware of the system that is powering your model. \"), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"768px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/42dc0a59982cc44cb01338bbe61d059e/2cefc/model_retraining.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"56.25%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdklEQVQoz31SWW7jMAzN/S/YrxZx66ZaKMkTb7Qs8RWy7Ew9mJQAQXHR43oBIAcX+qn/z/aMDt/lfr+LtQYpJaBaUf14SGaG1nqTz2iPlcs0jfLethiZa5Z/qii2dV2l/bzJn76vekpiiEQbI19KybwssoPKpUirLBZyghjL759pH1USebAlICU0r6/wzRWp7xGIcH15kT22AqoCOI6C/o4cwsYS46ltpQnzMAI8wzcNhq4rs8BiLVTTnCvU1iGuSR6FxYjsHGSacBhLDO9JDoprQtpnl48ZboDGYVliGR8k57rOnJGHATnnB+DMy/YutmN5aV2LLnICtG4z4hdSxmFd09Mln1q+KYv2y4jxHbQLlSlAW4+368d2UuQ7tDcNQ9WvKEC5gPLnU5NY5/9WmHIGj6OULbLz4K4Dew/ue5DziGV2AvASwcO4bZtDByYH9gGTJfEH4NE8UhI4B3gPhACULc7z6YQ2KmdlTY0hW+NCqC1Pk3wDdBRamF5T7VwAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Model Retraining\",\n    \"title\": \"Model Retraining\",\n    \"src\": \"/static/42dc0a59982cc44cb01338bbe61d059e/e5715/model_retraining.png\",\n    \"srcSet\": [\"/static/42dc0a59982cc44cb01338bbe61d059e/8514f/model_retraining.png 192w\", \"/static/42dc0a59982cc44cb01338bbe61d059e/804b2/model_retraining.png 384w\", \"/static/42dc0a59982cc44cb01338bbe61d059e/e5715/model_retraining.png 768w\", \"/static/42dc0a59982cc44cb01338bbe61d059e/4ad3a/model_retraining.png 1152w\", \"/static/42dc0a59982cc44cb01338bbe61d059e/2cefc/model_retraining.png 1400w\"],\n    \"sizes\": \"(max-width: 768px) 100vw, 768px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"Model Retraining\"), \"\\n  \"), mdx(\"h4\", null, \"Pipelines\"), mdx(\"p\", null, \"This can be tricky for the DevOps/IT team to monitor unless the data scientists communicate what the model expects while the team can tell us what the pipeline should output. \"), mdx(\"p\", null, \"We can monitor the input data's schema and completeness, while implementing validation checks on the data with the right alerts being sent whenever the data starts to drift.\"), mdx(\"p\", null, \"The intermediate workflow steps, also called DAGs or CRON jobs, should be monitored too. Metrics such as run time, file types, file sizes, state of job, data distribution, number of features etc. should closely align or exactly match what we expect.\"), mdx(\"p\", null, \"Finally, the output data schema schema and completeness should also be monitored so it does not cause failures further down the pipeline.\"), mdx(\"h2\", null, \"Conclusion\"), mdx(\"p\", null, \"A lot of what has been written in this blog may seem obvious but you would be surprised on how almost none of this is being practiced. Thus, I start this conclusion by recommending that you encourage your team to incorporate a monitoring strategy and properly document their decision process. Centralize your monitoring so it is under one platform, ideally one that has many of the basic metrics out-of-the-shelf. Meanwhile, decentralize the monitoring power so that data professionals and Ops engineers communicate frequently between one another creates a decentralized knowledge structure. \"), mdx(\"p\", null, \"Monitoring is about collecting the dots, observability is about connecting them! Once we observe any type of drift we should alert the right people and log this information. Monitoring is never the final step and should be thought about from the very start.\"), mdx(\"p\", null, \"Overall, with proper monitoring we can ensure that model performance is optimal throughout it's deployment and never drifts when subject to many production level issues.\"), mdx(\"p\", null, \"To learn more, I would recommend reading Google Cloud's documentation on CI/CD for ML systems \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"here\"), \". The three levels of MLOps can clarify what needs to be developed in your ML pipeline and what you can do to build it, below is an image of level 2 - a robust and automated CI/CD system.\"), mdx(\"figure\", {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"768px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/b0c0b628075618ac88bd6a50a15dbe7c/c9d77/CI_CD_System.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"67.1875%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACB0lEQVQ4y42T627cIBCF9/0frf8bVWqTKt3s2l4bGy/GwHD5KvBWadRWKtJ44MzxwNxOpRTe17FPYWadniA7/m8VfHBUX6f68fuIOMVdMkpg2Czfhx4VEkoKxjsWrbG7Y9v2ppX1nBfDRd8xdmcZLcGn6jCz6R/47YqOhVuEixW+3jS9L3ShsIZIP9y4bxu3UaFmTXffebqOfJs0Zo8svSE44ZRzRvmdVQKbuTPeBtQ0Yo2Bmo6SqZdWXkqp6ZwTJedHigpbED73E8tuOUmMfBnOvMw9IQQ2a7F2x3n/+Plw5EMgxkjlVx1E2L1HRLBeeOk1xkVOFXi7z3Sb/muyD5UpKX2wRBFeX8+E4Ikh071MeCuHQ0mRXApaMr1LjFKYIkwCU4JR4BbeMdWw0nI8+4CPiZtL2OAPhzWkGkJvA+dpoXOJqzZcrXDRG93muRjHdbUHNq+N8zavTD6x+Mini2LcHy/MKRMlNsNkbGuXadtR9bw51B6Y9sBsPcqng+MTgzaskrGp8Lz6tm8ON+9wMbSM1dqlUggx4yS2cHYvWHeEVrFqS7kc/MdgxEcHnGrF3vREd58fBSjNoFfDog3zstJ1A8Mwtn3Fqi21IhV+TVpu7VWOF9aeqocPUu8vBcnwPK5NnMij9r/z6qgK6tuZaN17Uf4lkhL9apvUkP/g5EQMgukVyQs/ARLD83iFPNwXAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"A Robust CI/CD System\",\n    \"title\": \"A Robust CI/CD System\",\n    \"src\": \"/static/b0c0b628075618ac88bd6a50a15dbe7c/e5715/CI_CD_System.png\",\n    \"srcSet\": [\"/static/b0c0b628075618ac88bd6a50a15dbe7c/8514f/CI_CD_System.png 192w\", \"/static/b0c0b628075618ac88bd6a50a15dbe7c/804b2/CI_CD_System.png 384w\", \"/static/b0c0b628075618ac88bd6a50a15dbe7c/e5715/CI_CD_System.png 768w\", \"/static/b0c0b628075618ac88bd6a50a15dbe7c/4ad3a/CI_CD_System.png 1152w\", \"/static/b0c0b628075618ac88bd6a50a15dbe7c/71c1d/CI_CD_System.png 1536w\", \"/static/b0c0b628075618ac88bd6a50a15dbe7c/c9d77/CI_CD_System.png 1964w\"],\n    \"sizes\": \"(max-width: 768px) 100vw, 768px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", {\n    parentName: \"figure\",\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }, \"A Robust CI/CD System\"), \"\\n  \"), mdx(\"p\", null, \"Further Reading:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://databricks.com/fr/glossary/mlops\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"What is ML Ops?\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"CI/CD for ML systems on Google Cloud\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://neptune.ai/blog/how-to-monitor-your-models-in-production-guide\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"ML Production Guide\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://towardsdatascience.com/using-statistical-distance-metrics-for-machine-learning-observability-4c874cded78\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"ML Observability\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://towardsdatascience.com/machine-learning-in-production-why-you-should-care-about-data-and-concept-drift-d96d0bc907fb\",\n    \"target\": \"_blank\",\n    \"rel\": \"nofollow noopener noreferrer\"\n  }, \"Types of Model Drift\"))));\n}\n;\nMDXContent.isMDXComponent = true;","timeToRead":7,"excerpt":"Introduction Traditional software application code is deterministic and always runs as written. When you deploy new code, hopefully, all the…","frontmatter":{"title":"ML Ops","description":"Performing a Statistic tests","cover":{"publicURL":"/static/2b44e885d0cc83feea72f90c2496bba4/MLOps.png","childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB90lEQVQ4y4WU63LaMBCF8/4vkr/tnz5DZ9rMtA2kIbYh+IqsCzYY8FVfxyaA3WRazawtrVZH53jO+g7oOA/LaFg7WfKfvUuiu7sA2muVvR5o25bFYoHv+wRhgJQSa7u+YgJ6O/sGeF6Pn9dKFs/POI7DbDbDddyJjr72rf6COWI4uqhuLdmxwRwaKgtN29G2DTUVuzKjqHY0XT0GvTG01nbjZH6seZUFa3Ug0EcCU7HcGAK1Jt3HxFlAtPWJtz6Han+V/IYxldwz85KM7zOHh7nLz5f+YMVL7OMlS8xJsUpcHl9+MHd/ERmf+sz0JvnCsE/2MlfpnrkX8eiGzNyApdR8Wf8eIszXqCJBFgJVCMQ+Zl/mV8CB4RjQFDWhKUmymjgr2egtjhLcr564X81ZbV1U7g3SZbFB7CPy03YKeJOMzU8NgSmJs4pIZ8RK4SvJp8Tjc+KSZC4yc0nz14Gl2EUU5+/4seS2syRZNbCMtSHSio3WfBUR36SD6dnlHjJfDux62V3Xvmc4vqJuOkReEko1xMZoRBqg9AK98xCZM4Q+pDRt/S9j3/L9qzxpDrsQIz1874G1+0CmHE7FiroUXPvqI2OPfTjMz/amOwak4SMyfsKIZ9JwRlMEQMO4qy4+nHTKlOEZ1PYeazU0App0mPe5v8AmP4c/Mfg58YyMyE8AAAAASUVORK5CYII="},"backgroundColor":"transparent","images":{"fallback":{"src":"/static/2b44e885d0cc83feea72f90c2496bba4/893e2/MLOps.png","srcSet":"/static/2b44e885d0cc83feea72f90c2496bba4/d62fd/MLOps.png 640w,\n/static/2b44e885d0cc83feea72f90c2496bba4/907ac/MLOps.png 1280w,\n/static/2b44e885d0cc83feea72f90c2496bba4/893e2/MLOps.png 2560w","sizes":"(min-width: 2560px) 2560px, 100vw"},"sources":[{"srcSet":"/static/2b44e885d0cc83feea72f90c2496bba4/63f5e/MLOps.avif 640w,\n/static/2b44e885d0cc83feea72f90c2496bba4/2564e/MLOps.avif 1280w,\n/static/2b44e885d0cc83feea72f90c2496bba4/9216f/MLOps.avif 2560w","type":"image/avif","sizes":"(min-width: 2560px) 2560px, 100vw"},{"srcSet":"/static/2b44e885d0cc83feea72f90c2496bba4/f3a51/MLOps.webp 640w,\n/static/2b44e885d0cc83feea72f90c2496bba4/fb953/MLOps.webp 1280w,\n/static/2b44e885d0cc83feea72f90c2496bba4/c4a92/MLOps.webp 2560w","type":"image/webp","sizes":"(min-width: 2560px) 2560px, 100vw"}]},"width":2560,"height":1840}}},"coverAlt":"Ml Ops","datePublished":"2022-06-05","dateModified":"2022-06-05","category":"Ops","tags":["Machine Learning","DevOps"]},"fields":{"slug":"/ml-ops","route":"/ml-ops","pathName":"ml-ops","url":"https://ashishthanki.github.io/ml-ops"},"internal":{"content":"---\ntitle: \"ML Ops\"\ncover: images/MLOps/MLOps.png\ncoverAlt: \"Ml Ops\"\ndescription: \"Performing a Statistic tests\"\ndatePublished: \"2022-06-05\"\ndateModified: \"2022-06-05\"\ncategory: \"Ops\"\ntags:\n  - Machine Learning\n  - DevOps\n---\n\n# Introduction\n\nTraditional software application code is deterministic and always runs as written. When you deploy new code, hopefully, all the rigorous tests you've written, work and catch any bugs allowing the application to continue to work as expected. However, the world of machine learning is different. Machine learning models are dynamic and, thus, they degrade overtime after being deployed to production. They are sensitive to real changes to the world. A model is at it's best just before being deployed.\n\nThere are two levels for monitoring a machine learning model in production: Functional Level monitoring and Operational Level monitoring.\n\nFunctional monitoring involves monitoring the model performance, input, and output.\nOperational monitoring involves monitoring at the system and resource levels.\n\n![ML Ops Cycle](images/MLOps/MLOps_Cycle.png)\n\n## Functional monitoring\n\nThis is typically the responsibility of the data scientist where we must monitor the input data, the prediction made by the model, and what goes inside the model while making that prediction during production (see my [Model Interpreting](./interpreting-ml-models-part-2) blog).\n\nThere are many possible problems that can cause poor model predictions along the data pipeline. Although many of these processes requires input from the data scientist. We must ensure other teams are alerted so a holistic, longer term solution, can be deployed rather than a code patch from the data scientist.\n\n### Input Data\nMonitoring the input data ensures the model gets what the data scientist expected when the model was first trained. Any deviation from this will cause poor predictions (GIGO - garbage in garbage out) - which is why we need to ensure we monitor the data before it even passes into model.\n\nThere are three cases you may want to monitor the input data:\n\n##### 1. Data Quality issues:\nMonitoring data properties we can ensure that a flag, or an alert, is triggered when the data is not what we expect so that the data team or service owner can take a look.\n\nThese can also be caused by preprocessing steps within the data pipeline, changes in source data (e.g. data schema change, column renaming), or data loss/corruption.\n\nTo name a few examples, we can write numerous tests to detect data quality issues:\n\n- Duplicates;\n- Missing values;\n- Syntax errors;\n- Data type or format errors;\n- Schema changes;\n- Data profiling;\n\nThis list can go on and on for tabular datasets but also extends out to include visual, audio and video based data types.\n\n##### 2. Data Drift:\nMonitoring data drift is an important part of functional monitoring. We can understand ahead of time when the data is changing and retrain the model to the change in distribution between the training data and production data. This process typically happens over time. \n\nThese changes are particularly common in features, thus, we must pay close attention to changes in individual features too.\n\nDescriptive statistics can be used: measure of central tendency,  measure of variability, measure of frequency and measure of position - read more at my blog post [here](./#12-StatsTests) and this *towardsdatascience* blog [here](https://towardsdatascience.com/using-statistical-distance-metrics-for-machine-learning-observability-4c874cded78). We would need to understand the domain and use relevant metrics to ensure the features do not degrade model performance. For example, these properties could include standard deviation, mean, mode, median and so on. \n\nTo detect data drift we can introduce distribution tests into pipeline such as divergence, distance, or, categorical tests. The output of these tests can then form the foundation of measuring these changes, alert the service owner, start a retraining cycle, alert the data scientist to build a new model, or build a challenger model and then perform A/B testing against the deployed one.\n\n##### 3. Outliers:\nOutliers do not have a learnable structure across an entire dataset so will cause the model to return unreliable responses. It is one of the hardest data issues to detect, because extreme values can be a one off event and difficult to handle through rules.\n\nWe can attempt to detect outliers by performing tests similiar to that of the data drift ones, create a supervised learning, or use autoML to detect outliers.\n\nThe solutions may involve data slicing and analysing model performance on each subset of the data (i\\.e\\. cross validation folds), understand when the outlier occurs (by performing analysis) and introduce rules or human intervention to assist with the decision process for that period.\n\n### Model\nThe input data is arguably one that could change the most. However, the model is the most important piece to monitor. \n\n##### 1. Monitoring Model drift\nSimilar to data drift, model drift occurs when the relationship between the features and the target no longer holds due to changes over time. The model predictions become increasingly unreliable and less accurate over time, and no longer meet the benchmark, business metrics and KPIs set out.\n\n\n![Model Drift Example due to COVID-19](images/MLOps/model_drift.png)\n\nThere are several types of model drift:\n\n- Instantaneous model drift, a sudden drop in model performance caused by input data issues. An example of this is when COVID-19 lockdowns started, input data changed rapidly while predictions made by the model could not keep up. \n- Gradual model drift occurs when data changes over time as a result of external factors such as user behaviour changes, new features, or new demographics. \n- Recurring model drift is caused by seasonal events that occur periodically. For example, holidays, yearly discounts or customer spikes in regions.\n- Temporary model drift occurs during strange, one-off events. For example, the model temporarily drops in performance because of a spike in newer clients, system performance issues, or adversarial attacks before returning back to normal levels.\n\nTo monitor model drift we can set the predictive metrics threshold and either perform hyperparameter optimisation, retrain the model, send an alert when we need to analyze the model for degradations or drifts, or, more challengingly, use online learning algorithms.\n\n##### 2. Model Configuration and Artifacts\n\nJust like any other report or business document, we need to keep track of all configurations related to our model. This can aid in replication and help use replicate our work for others. The configuration file contains model information, version, author, hyperparameters, dependencies, features values and more. This can help us understand when things started going wrong and why.\n\nTying the configuration with the deployed model version is a great way of ensuring the right model is deployed.\n\n##### 3. Concerted adversaries\n\nMachine learning models are susceptible to adversarial attacks. They vigorously attack your system/model so it makes a mistake. To monitor these sort of attacks we need to flag inputs with outlier events, it is common for adversarial attacks to be atypical events. Another possibility is adding human intervention to the pipeline whenever a marginally detected anomalous event occurs within the input data. We could also add business logic to the pipeline and modelling so that subject expert knowledge on adversarial attacks can be incorporated. \n\n### Predictions\n\nMonitoring the predictions that the model outputs can provide many useful insights and allow us to compare it to business KPIs.\n\n##### 1. Model evaluation metrics\n\nDifferent machine learning problems require the use of different metrics such as regression, classification, clustering, reinforcement learning, computer vision and so on. We should monitor metrics most relevant to the machine learning problem that we are trying to solve and the business KPIs.\n\nAs you probably already know, metrics for a classification model include:\n\n- Accuracy\n- Confusion Matrix,\n- ROC-AUC Score,\n- Precision and Recall Scores,\n- F1-Score.\n\nMetrics for a regression model include:\n\n- Root Mean Square Error (RMSE),\n- R-Squared, Adjusted R-Squared and Normalized R-Squared Metrics,\n- Mean Absolute Error (MAE),\n- Mean Absolute Percentage Error (MAPE).\n\n##### 2. Truth Labels\n\nIt is sometimes unclear whether true labels will be present when predictions have been made, or, real time model metrics are even possible at all and a delayed metric is reported instead. Comparing actual labels to predictions in production is a very difficult task in most cases.\n\nWhen true labels are not available we can catch monitor the prediction distribution as this should have been set to the business KPI.\n\n\n## Operational level monitoring\n\nThe system monitoring and operation typically falls under the responsibility of the IT operations team but this has to be a shared responsibility when it comes to machine learning and deployment of models. Data scientist should be responsible for monitoring model performance and data coming into the model. \n\n#### System performance monitoring\n\nThis is primarily an infrastructure problem. We need to make sure that the application's latency, uptime, scalability, adaptability, extensibility etc are monitored and metrics are being tracked. Understanding these key metrics can help data scientists if their model has high latency in returning predictions, which may have affected the overall application's speed.\n\nThe metrics that may be worth monitoring include, but not limited to: CPU/GPU utilization, memory utilization, failed requests, API calls, and response time. This may not be the direct responsibility but it's extremely helpful to be aware of the system that is powering your model. \n\n![Model Retraining](images/MLOps/model_retraining.png)\n\n#### Pipelines\n\nThis can be tricky for the DevOps/IT team to monitor unless the data scientists communicate what the model expects while the team can tell us what the pipeline should output. \n\nWe can monitor the input data's schema and completeness, while implementing validation checks on the data with the right alerts being sent whenever the data starts to drift.\n\nThe intermediate workflow steps, also called DAGs or CRON jobs, should be monitored too. Metrics such as run time, file types, file sizes, state of job, data distribution, number of features etc. should closely align or exactly match what we expect.\n\nFinally, the output data schema schema and completeness should also be monitored so it does not cause failures further down the pipeline.\n\n\n\n## Conclusion\n\nA lot of what has been written in this blog may seem obvious but you would be surprised on how almost none of this is being practiced. Thus, I start this conclusion by recommending that you encourage your team to incorporate a monitoring strategy and properly document their decision process. Centralize your monitoring so it is under one platform, ideally one that has many of the basic metrics out-of-the-shelf. Meanwhile, decentralize the monitoring power so that data professionals and Ops engineers communicate frequently between one another creates a decentralized knowledge structure. \n\nMonitoring is about collecting the dots, observability is about connecting them! Once we observe any type of drift we should alert the right people and log this information. Monitoring is never the final step and should be thought about from the very start.\n\nOverall, with proper monitoring we can ensure that model performance is optimal throughout it's deployment and never drifts when subject to many production level issues.\n\n\nTo learn more, I would recommend reading Google Cloud's documentation on CI/CD for ML systems [here](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning). The three levels of MLOps can clarify what needs to be developed in your ML pipeline and what you can do to build it, below is an image of level 2 - a robust and automated CI/CD system.\n\n![A Robust CI/CD System](images/MLOps/CI_CD_System.png)\n\n\nFurther Reading:\n\n\n- [What is ML Ops?](https://databricks.com/fr/glossary/mlops)\n- [CI/CD for ML systems on Google Cloud](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\n- [ML Production Guide](https://neptune.ai/blog/how-to-monitor-your-models-in-production-guide)\n- [ML Observability](https://towardsdatascience.com/using-statistical-distance-metrics-for-machine-learning-observability-4c874cded78)\n- [Types of Model Drift](https://towardsdatascience.com/machine-learning-in-production-why-you-should-care-about-data-and-concept-drift-d96d0bc907fb)\n"}}},"pageContext":{"slug":"/ml-ops","nexttitle":"Performing Stats Tests","nextslug":"/performing-stats-tests","prevtitle":"Stranger Methods","prevslug":"/stranger-methods","relatedPosts":[{"title":"ML Ops","description":"Performing a Statistic tests","coverImg":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB90lEQVQ4y4WU63LaMBCF8/4vkr/tnz5DZ9rMtA2kIbYh+IqsCzYY8FVfxyaA3WRazawtrVZH53jO+g7oOA/LaFg7WfKfvUuiu7sA2muVvR5o25bFYoHv+wRhgJQSa7u+YgJ6O/sGeF6Pn9dKFs/POI7DbDbDddyJjr72rf6COWI4uqhuLdmxwRwaKgtN29G2DTUVuzKjqHY0XT0GvTG01nbjZH6seZUFa3Ug0EcCU7HcGAK1Jt3HxFlAtPWJtz6Han+V/IYxldwz85KM7zOHh7nLz5f+YMVL7OMlS8xJsUpcHl9+MHd/ERmf+sz0JvnCsE/2MlfpnrkX8eiGzNyApdR8Wf8eIszXqCJBFgJVCMQ+Zl/mV8CB4RjQFDWhKUmymjgr2egtjhLcr564X81ZbV1U7g3SZbFB7CPy03YKeJOMzU8NgSmJs4pIZ8RK4SvJp8Tjc+KSZC4yc0nz14Gl2EUU5+/4seS2syRZNbCMtSHSio3WfBUR36SD6dnlHjJfDux62V3Xvmc4vqJuOkReEko1xMZoRBqg9AK98xCZM4Q+pDRt/S9j3/L9qzxpDrsQIz1874G1+0CmHE7FiroUXPvqI2OPfTjMz/amOwak4SMyfsKIZ9JwRlMEQMO4qy4+nHTKlOEZ1PYeazU0App0mPe5v8AmP4c/Mfg58YyMyE8AAAAASUVORK5CYII="},"backgroundColor":"transparent","images":{"fallback":{"src":"/static/2b44e885d0cc83feea72f90c2496bba4/49665/MLOps.png","srcSet":"/static/2b44e885d0cc83feea72f90c2496bba4/b60fd/MLOps.png 128w,\n/static/2b44e885d0cc83feea72f90c2496bba4/c430c/MLOps.png 256w,\n/static/2b44e885d0cc83feea72f90c2496bba4/49665/MLOps.png 512w,\n/static/2b44e885d0cc83feea72f90c2496bba4/5cd3f/MLOps.png 1024w","sizes":"(min-width: 512px) 512px, 100vw"},"sources":[{"srcSet":"/static/2b44e885d0cc83feea72f90c2496bba4/cb84f/MLOps.avif 128w,\n/static/2b44e885d0cc83feea72f90c2496bba4/29603/MLOps.avif 256w,\n/static/2b44e885d0cc83feea72f90c2496bba4/2621b/MLOps.avif 512w,\n/static/2b44e885d0cc83feea72f90c2496bba4/acbd7/MLOps.avif 1024w","type":"image/avif","sizes":"(min-width: 512px) 512px, 100vw"},{"srcSet":"/static/2b44e885d0cc83feea72f90c2496bba4/8b374/MLOps.webp 128w,\n/static/2b44e885d0cc83feea72f90c2496bba4/0c1fc/MLOps.webp 256w,\n/static/2b44e885d0cc83feea72f90c2496bba4/614cb/MLOps.webp 512w,\n/static/2b44e885d0cc83feea72f90c2496bba4/e74f9/MLOps.webp 1024w","type":"image/webp","sizes":"(min-width: 512px) 512px, 100vw"}]},"width":512,"height":368},"coverImageAlt":"Ml Ops","datePublished":"2022-06-05T00:00:00.000Z","dateModified":"2022-06-05T00:00:00.000Z","category":"Ops","tags":["Machine Learning","DevOps"],"excerpt":"Introduction Traditional software application code is deterministic and always runs as written. When you deploy new code, hopefully, all the…","timeToRead":7,"slug":"/ml-ops","route":"/ml-ops","pathName":"ml-ops","url":"https://ashishthanki.github.io/ml-ops"},{"title":"Model Drift and Concept Drift","description":"Maintaining a good in-production model requires understanding the understanding of model and concept drift.","coverImg":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAEDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd1ORYA//8QAFxAAAwEAAAAAAAAAAAAAAAAAAAEQEf/aAAgBAQABBQKaOI//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAAIDH/2gAIAQEABj8CKv8A/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAERITFRQf/aAAgBAQABPyHNYn6IdFrWX1iQoP/aAAwDAQACAAMAAAAQA8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAgMBAQAAAAAAAAAAAAABABEhMXFBof/aAAgBAQABPxBVtSpsKgjtDxmHQ6xbodZwxdvtBMZ7P//Z"},"backgroundColor":"transparent","images":{"fallback":{"src":"/static/c21aa3f5b54bbb6c20eefa63c18b5086/7acdb/degradation-point.jpg","srcSet":"/static/c21aa3f5b54bbb6c20eefa63c18b5086/76a0b/degradation-point.jpg 148w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/f5d63/degradation-point.jpg 295w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/7acdb/degradation-point.jpg 590w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/cc266/degradation-point.jpg 1180w","sizes":"(min-width: 590px) 590px, 100vw"},"sources":[{"srcSet":"/static/c21aa3f5b54bbb6c20eefa63c18b5086/8ec5f/degradation-point.avif 148w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/24e48/degradation-point.avif 295w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/23579/degradation-point.avif 590w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/630d8/degradation-point.avif 1180w","type":"image/avif","sizes":"(min-width: 590px) 590px, 100vw"},{"srcSet":"/static/c21aa3f5b54bbb6c20eefa63c18b5086/a168a/degradation-point.webp 148w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/6e9d7/degradation-point.webp 295w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/7b043/degradation-point.webp 590w,\n/static/c21aa3f5b54bbb6c20eefa63c18b5086/f3c07/degradation-point.webp 1180w","type":"image/webp","sizes":"(min-width: 590px) 590px, 100vw"}]},"width":590,"height":368},"coverImageAlt":"Deployed models have a degradation point and we need to avoid it!","datePublished":"2023-07-31T00:00:00.000Z","dateModified":"2023-07-31T00:00:00.000Z","category":"Ops","tags":["Machine Learning","DevOps"],"excerpt":"Model drift is a silent killer for in-production models and something that data scientists need to be mindful of. The importance of MLOps…","timeToRead":4,"slug":"/model-drift-and-concept-drift","route":"/model-drift-and-concept-drift","pathName":"/model-drift-and-concept-drift","url":"https://ashishthanki.github.io/model-drift-and-concept-drift"}]}},
    "staticQueryHashes": ["3661114550"]}