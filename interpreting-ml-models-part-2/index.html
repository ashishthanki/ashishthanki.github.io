<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.87a48dcf824f9cb477ef.css" data-identity="gatsby-global-css">code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#f8f8f2;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;text-align:left;text-shadow:0 1px rgba(0,0,0,.3);white-space:pre;word-break:normal;word-spacing:normal}pre[class*=language-]{border-radius:.3em;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#282a36}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#6272a4}.token.punctuation{color:#f8f8f2}.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#ff79c6}.token.boolean,.token.number{color:#bd93f9}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#50fa7b}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#f1fa8c}.token.keyword{color:#8be9fd}.token.important,.token.regex{color:#ffb86c}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.command-line-prompt{border-right:1px solid #999;display:block;float:left;font-size:100%;letter-spacing:-1px;margin-right:1em;pointer-events:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}.command-line-prompt>span:before{color:#999;content:" ";display:block;padding-right:.8em}.command-line-prompt>span[data-user]:before{content:"[" attr(data-user) "@" attr(data-host) "] $"}.command-line-prompt>span[data-user=root]:before{content:"[" attr(data-user) "@" attr(data-host) "] #"}.command-line-prompt>span[data-prompt]:before{content:attr(data-prompt)}</style><meta name="generator" content="Gatsby 4.0.0"/><style data-styled="" data-styled-version="5.3.3">h1{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:32px;line-height:40px;-webkit-letter-spacing:0.25px;-moz-letter-spacing:0.25px;-ms-letter-spacing:0.25px;letter-spacing:0.25px;}/*!sc*/
@media (min-width:564px){h1{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:47px;line-height:56px;}}/*!sc*/
h2{font-family:"Fira Code",serif;font-style:normal;font-weight:normal;font-size:29px;line-height:40px;-webkit-letter-spacing:0px;-moz-letter-spacing:0px;-ms-letter-spacing:0px;letter-spacing:0px;}/*!sc*/
@media (min-width:564px){h2{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:39px;line-height:48px;}}/*!sc*/
h3{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:26px;line-height:32px;-webkit-letter-spacing:0.15px;-moz-letter-spacing:0.15px;-ms-letter-spacing:0.15px;letter-spacing:0.15px;}/*!sc*/
@media (min-width:564px){h3{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:33px;line-height:40px;-webkit-letter-spacing:0.15px;-moz-letter-spacing:0.15px;-ms-letter-spacing:0.15px;letter-spacing:0.15px;}}/*!sc*/
h4{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:23px;line-height:32px;-webkit-letter-spacing:0.25px;-moz-letter-spacing:0.25px;-ms-letter-spacing:0.25px;letter-spacing:0.25px;}/*!sc*/
@media (min-width:564px){h4{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:27px;line-height:32px;-webkit-letter-spacing:0.25px;-moz-letter-spacing:0.25px;-ms-letter-spacing:0.25px;letter-spacing:0.25px;}}/*!sc*/
h5{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:20px;line-height:24px;-webkit-letter-spacing:0.35px;-moz-letter-spacing:0.35px;-ms-letter-spacing:0.35px;letter-spacing:0.35px;}/*!sc*/
@media (min-width:564px){h5{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:23px;line-height:32px;-webkit-letter-spacing:0.35px;-moz-letter-spacing:0.35px;-ms-letter-spacing:0.35px;letter-spacing:0.35px;}}/*!sc*/
h6{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:18px;line-height:24px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;}/*!sc*/
@media (min-width:564px){h6{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:19px;line-height:24px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;}}/*!sc*/
p{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:16px;line-height:24px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}/*!sc*/
@media (min-width:564px){p{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:18px;line-height:28px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}}/*!sc*/
button{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:500;font-size:18px;line-height:16px;-webkit-letter-spacing:1.25px;-moz-letter-spacing:1.25px;-ms-letter-spacing:1.25px;letter-spacing:1.25px;text-transform:uppercase;}/*!sc*/
code{font-family:"Fira Code",monospace !important;font-size:14px !important;line-height:21px !important;}/*!sc*/
@media (min-width:564px){code{font-family:"Fira Code",monospace !important;font-size:16px !important;line-height:24px !important;}}/*!sc*/
data-styled.g1[id="sc-global-ccfKnH1"]{content:"sc-global-ccfKnH1,"}/*!sc*/
:root{--color-primary-100:#e88896;--color-primary-200:#e47485;--color-primary-300:#e06073;--color-primary-400:#dc4c62;--color-primary:#d83850;--color-primary-600:#c23248;--color-primary-700:#ad2d40;--color-primary-800:#972738;--color-primary-900:#822230;--color-grey-100:#f7f7f7;--color-grey-200:#dbdbdb;--color-grey-300:#c0c0c0;--color-grey-400:#adadad;--color-grey-500:#9a9a9a;--color-grey-600:#6e6e6e;--color-grey-700:#414141;--color-grey-800:#2e2e2e;--color-grey-900:#1a1a1a;--color-text:#000000;--color-inverted-text:#ffffff;--color-background:#ffffff;--color-inverted-background:#000000;}/*!sc*/
data-styled.g2[id="sc-global-yNOOY1"]{content:"sc-global-yNOOY1,"}/*!sc*/
*{-webkit-scrollbar-color:var(--color-grey-500) var(--color-background);-moz-scrollbar-color:var(--color-grey-500) var(--color-background);-ms-scrollbar-color:var(--color-grey-500) var(--color-background);scrollbar-color:var(--color-grey-500) var(--color-background);}/*!sc*/
*::-webkit-scrollbar{width:12px;height:12px;}/*!sc*/
*::-webkit-scrollbar-track{background:var(--color-background);}/*!sc*/
*::-webkit-scrollbar-thumb{background:var(--color-grey-500);border-radius:6px;border:2px solid var(--color-background);}/*!sc*/
*::-webkit-scrollbar-thumb:hover{background:var(--color-primary-100);}/*!sc*/
*::-webkit-scrollbar-thumb:active{background:var(--color-primary);}/*!sc*/
data-styled.g3[id="sc-global-gtdreK1"]{content:"sc-global-gtdreK1,"}/*!sc*/
html{box-sizing:border-box;}/*!sc*/
*,*:before,*:after{box-sizing:inherit;margin:0;padding:0;}/*!sc*/
body{margin:0;padding:0;min-height:100%;min-width:100%;}/*!sc*/
#___gatsby #gatsby-focus-wrapper{min-height:100vh;min-width:100%;}/*!sc*/
data-styled.g4[id="sc-global-bwVVwl1"]{content:"sc-global-bwVVwl1,"}/*!sc*/
.hdUndc{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:32px;line-height:40px;-webkit-letter-spacing:0.25px;-moz-letter-spacing:0.25px;-ms-letter-spacing:0.25px;letter-spacing:0.25px;}/*!sc*/
@media (min-width:564px){.hdUndc{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:47px;line-height:56px;}}/*!sc*/
data-styled.g5[id="Primitives__H1-sc-1kfaxvk-0"]{content:"hdUndc,"}/*!sc*/
.hTdBcY{font-family:"Fira Code",serif;font-style:normal;font-weight:normal;font-size:29px;line-height:40px;-webkit-letter-spacing:0px;-moz-letter-spacing:0px;-ms-letter-spacing:0px;letter-spacing:0px;}/*!sc*/
@media (min-width:564px){.hTdBcY{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:39px;line-height:48px;}}/*!sc*/
data-styled.g6[id="Primitives__H2-sc-1kfaxvk-1"]{content:"hTdBcY,"}/*!sc*/
.eEpwqO{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:26px;line-height:32px;-webkit-letter-spacing:0.15px;-moz-letter-spacing:0.15px;-ms-letter-spacing:0.15px;letter-spacing:0.15px;}/*!sc*/
@media (min-width:564px){.eEpwqO{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:33px;line-height:40px;-webkit-letter-spacing:0.15px;-moz-letter-spacing:0.15px;-ms-letter-spacing:0.15px;letter-spacing:0.15px;}}/*!sc*/
data-styled.g7[id="Primitives__H3-sc-1kfaxvk-2"]{content:"eEpwqO,"}/*!sc*/
.fNseVF{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:23px;line-height:32px;-webkit-letter-spacing:0.25px;-moz-letter-spacing:0.25px;-ms-letter-spacing:0.25px;letter-spacing:0.25px;}/*!sc*/
@media (min-width:564px){.fNseVF{font-family:"Alfa Slab One",serif;font-style:normal;font-weight:normal;font-size:27px;line-height:32px;-webkit-letter-spacing:0.25px;-moz-letter-spacing:0.25px;-ms-letter-spacing:0.25px;letter-spacing:0.25px;}}/*!sc*/
data-styled.g8[id="Primitives__H4-sc-1kfaxvk-3"]{content:"fNseVF,"}/*!sc*/
.eKNIHW{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:16px;line-height:24px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}/*!sc*/
@media (min-width:564px){.eKNIHW{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:18px;line-height:28px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}}/*!sc*/
data-styled.g11[id="Primitives__Body-sc-1kfaxvk-6"]{content:"eKNIHW,"}/*!sc*/
.ksrFqo{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:12px;line-height:16px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}/*!sc*/
@media (min-width:564px){.ksrFqo{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:14px;line-height:16px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;}}/*!sc*/
data-styled.g12[id="Primitives__Caption-sc-1kfaxvk-7"]{content:"ksrFqo,"}/*!sc*/
.kInRwt{display:inline-block;-webkit-text-decoration:none;text-decoration:none;color:var(--color-primary);background-color:inherit;}/*!sc*/
.kInRwt:after{display:block;content:"";width:100%;height:2px;background-color:var(--color-primary);-webkit-transition:-webkit-transform 300ms ease;-webkit-transition:transform 300ms ease;transition:transform 300ms ease;-webkit-transform:scaleX(0);-ms-transform:scaleX(0);transform:scaleX(0);}/*!sc*/
.kInRwt:hover{color:var(--color-primary);}/*!sc*/
.kInRwt:hover::after{-webkit-transform:scaleX(1);-ms-transform:scaleX(1);transform:scaleX(1);}/*!sc*/
.kInRwt.gatsby-active-link:after{-webkit-transform:scaleX(1);-ms-transform:scaleX(1);transform:scaleX(1);}/*!sc*/
data-styled.g15[id="styles__AnimatedLink-sc-1478t26-0"]{content:"kInRwt,"}/*!sc*/
.jMACNl{-webkit-text-decoration:none;text-decoration:none;color:inherit;width:100%;}/*!sc*/
data-styled.g16[id="styles__TransparentLink-sc-1478t26-1"]{content:"jMACNl,"}/*!sc*/
.glUXfQ{display:inline-block;-webkit-text-decoration:none;text-decoration:none;color:var(--color-primary);}/*!sc*/
.glUXfQ:hover{color:var(--color-primary);}/*!sc*/
data-styled.g17[id="styles__PrimaryLink-sc-1478t26-2"]{content:"glUXfQ,"}/*!sc*/
.gbJBje{color:var(--color-grey-700);}/*!sc*/
.gbJBje:hover{color:var(--color-primary);}/*!sc*/
data-styled.g18[id="styles__IconLink-sc-1478t26-3"]{content:"gbJBje,"}/*!sc*/
.gyiRkg{-webkit-text-decoration:none;text-decoration:none;color:inherit;}/*!sc*/
.gyiRkg:hover::before{content:"#";display:block;position:absolute;-webkit-transform:translateX(-100%);-ms-transform:translateX(-100%);transform:translateX(-100%);padding-right:8px;color:var(--color-primary);}/*!sc*/
data-styled.g19[id="styles__HeadingLink-sc-1478t26-4"]{content:"gyiRkg,"}/*!sc*/
.fHrGFt{display:inline-block;vertical-align:middle;overflow:hidden;}/*!sc*/
data-styled.g20[id="StyledIconBase-ea9ulj-0"]{content:"fHrGFt,"}/*!sc*/
.cUfcIF{display:grid;grid-auto-flow:column;gap:24px;}/*!sc*/
data-styled.g21[id="UserLinks__LinkGrid-sc-apim1l-0"]{content:"cUfcIF,"}/*!sc*/
.dA-DcVw{display:grid;gap:40px;justify-items:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding:32px 0px 16px;background-color:var(--color-grey-100);color:var(--color-grey-700);}/*!sc*/
data-styled.g22[id="styles__Wrapper-sc-1gphmby-0"]{content:"dA-DcVw,"}/*!sc*/
.bKLfTS{display:inline-grid;gap:12px;justify-items:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
data-styled.g23[id="styles__LinkGrid-sc-1gphmby-1"]{content:"bKLfTS,"}/*!sc*/
.eOeOIj{display:grid;gap:8px;justify-items:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
.eOeOIj a{color:var(--color-primary-600);}/*!sc*/
.eOeOIj a:hover{color:var(--color-primary-600);}/*!sc*/
data-styled.g24[id="styles__Info-sc-1gphmby-2"]{content:"eOeOIj,"}/*!sc*/
.wTDnd{-webkit-text-decoration:none;text-decoration:none;color:var(--color-text);display:grid;grid-auto-flow:column;grid-gap:16px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
data-styled.g25[id="style__HomeButton-sc-axaxo7-0"]{content:"wTDnd,"}/*!sc*/
.hA-dGla{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/
data-styled.g26[id="style__Wrapper-sc-axaxo7-1"]{content:"hA-dGla,"}/*!sc*/
.jAhXWb{display:grid;grid-auto-flow:column;grid-gap:24px;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}/*!sc*/
data-styled.g27[id="style__NavGrid-sc-axaxo7-2"]{content:"jAhXWb,"}/*!sc*/
.jWrjvl{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:500;font-size:18px;line-height:16px;-webkit-letter-spacing:1.25px;-moz-letter-spacing:1.25px;-ms-letter-spacing:1.25px;letter-spacing:1.25px;text-transform:uppercase;}/*!sc*/
@media (max-width:500px){.jWrjvl{display:none;}}/*!sc*/
data-styled.g28[id="style__SiteTitle-sc-axaxo7-3"]{content:"jWrjvl,"}/*!sc*/
.cbaIXU{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:500;font-size:18px;line-height:16px;-webkit-letter-spacing:1.25px;-moz-letter-spacing:1.25px;-ms-letter-spacing:1.25px;letter-spacing:1.25px;text-transform:uppercase;color:var(--color-text);}/*!sc*/
.cbaIXU:after{margin:8px 0 0 0;}/*!sc*/
data-styled.g29[id="style__NavButton-sc-axaxo7-4"]{content:"cbaIXU,"}/*!sc*/
.fwyrVH{width:100%;padding:0 16px 0 16px;justify-self:center;max-width:calc(1144px + 2 * 16px);}/*!sc*/
data-styled.g30[id="LayoutWidthContainer-sc-obprvr-0"]{content:"fwyrVH,"}/*!sc*/
.hYSJmR{min-height:100vh;min-width:100%;padding-top:16px;display:grid;grid-template-columns:100%;gap:80px;-webkit-align-content:space-between;-ms-flex-line-pack:space-between;align-content:space-between;}/*!sc*/
@media (max-width:564px){.hYSJmR{gap:40px;}}/*!sc*/
data-styled.g31[id="layouts__LayoutGrid-sc-wfe7y9-0"]{content:"hYSJmR,"}/*!sc*/
.coRloj{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:500;font-size:10px;line-height:16px;-webkit-letter-spacing:1.5px;-moz-letter-spacing:1.5px;-ms-letter-spacing:1.5px;letter-spacing:1.5px;text-transform:uppercase;text-transform:uppercase;}/*!sc*/
@media (min-width:564px){.coRloj{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:500;font-size:12px;line-height:16px;-webkit-letter-spacing:1.5px;-moz-letter-spacing:1.5px;-ms-letter-spacing:1.5px;letter-spacing:1.5px;text-transform:uppercase;}}/*!sc*/
.coRloj::before{content:"#";}/*!sc*/
data-styled.g33[id="styles__TagLink-sc-evad3c-0"]{content:"coRloj,"}/*!sc*/
.eyoDpl{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:12px;line-height:16px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;text-transform:capitalize;}/*!sc*/
@media (min-width:564px){.eyoDpl{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:14px;line-height:16px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;}}/*!sc*/
data-styled.g34[id="styles__CategoryLink-sc-evad3c-1"]{content:"eyoDpl,"}/*!sc*/
.kToWai{color:var(--color-grey-700);}/*!sc*/
data-styled.g35[id="styles__Caption-sc-evad3c-2"]{content:"kToWai,"}/*!sc*/
.duPBEk{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}/*!sc*/
data-styled.g36[id="styles__InfoGrid-sc-evad3c-3"]{content:"duPBEk,"}/*!sc*/
.eWUSCD{display:grid;grid-auto-flow:column;grid-gap:16px;}/*!sc*/
data-styled.g37[id="styles__TagGrid-sc-evad3c-4"]{content:"eWUSCD,"}/*!sc*/
.dofHQH{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/
data-styled.g38[id="styles__Wrapper-sc-evad3c-5"]{content:"dofHQH,"}/*!sc*/
.cNyHKV{object-fit:cover;box-shadow:inset 0px 0px 1px 1px rgba(0,0,0,0.1);}/*!sc*/
data-styled.g45[id="Image-sc-n1k2df-0"]{content:"cNyHKV,"}/*!sc*/
.irueSx{width:100%;height:368px;}/*!sc*/
@media (max-width:500px){.irueSx{height:320px;}}/*!sc*/
@media (max-width:440px){.irueSx{height:270px;}}/*!sc*/
.irueSx img{box-shadow:inset 0px 0px 1px 1px rgba(0,0,0,0.1);border-radius:10px;}/*!sc*/
data-styled.g46[id="styles__Cover-sc-ifqbpj-0"]{content:"irueSx,"}/*!sc*/
.dIefSC{display:grid;grid-gap:8px;}/*!sc*/
data-styled.g47[id="styles__Wrapper-sc-ifqbpj-1"]{content:"dIefSC,"}/*!sc*/
.eSQGhX{display:grid;grid-gap:12px;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-align-content:start;-ms-flex-line-pack:start;align-content:start;}/*!sc*/
data-styled.g48[id="styles__Header-sc-ifqbpj-2"]{content:"eSQGhX,"}/*!sc*/
.gNCZZM{display:-webkit-box;-webkit-line-clamp:2;-webkit-box-orient:vertical;overflow:hidden;}/*!sc*/
data-styled.g49[id="styles__Excerpt-sc-ifqbpj-3"]{content:"gNCZZM,"}/*!sc*/
.izGZyP{display:grid;grid-gap:12px;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-align-content:start;-ms-flex-line-pack:start;align-content:start;}/*!sc*/
data-styled.g50[id="styles__Meta-sc-ifqbpj-4"]{content:"izGZyP,"}/*!sc*/
.GlBhT{display:grid;}/*!sc*/
data-styled.g51[id="styles__Details-sc-ifqbpj-5"]{content:"GlBhT,"}/*!sc*/
.dOUrHM{width:100%;display:grid;grid-gap:80px;grid-template-columns:1fr 1fr;}/*!sc*/
@media (max-width:1100px){.dOUrHM{grid-template-columns:1fr;gap:60px;}}/*!sc*/
data-styled.g52[id="FeedListing__Wrapper-sc-xfguai-0"]{content:"dOUrHM,"}/*!sc*/
.hUCjhI{display:grid;grid-template-columns:100%;gap:80px;-webkit-align-content:space-between;-ms-flex-line-pack:space-between;align-content:space-between;justify-items:stretch;}/*!sc*/
data-styled.g53[id="FeedListing__WidthLimitedGrid-sc-xfguai-1"]{content:"hUCjhI,"}/*!sc*/
.cHsvLz{width:100%;padding:0;}/*!sc*/
@media (min-width:calc(736px + 2 * 16px)){.cHsvLz{padding:0 16px;max-width:calc(736px + 2 * 16px);}}/*!sc*/
data-styled.g56[id="Spacing__ExtendingWrapper-sc-1sl48mq-0"]{content:"cHsvLz,"}/*!sc*/
.hzIikw{width:100%;padding:0 16px;max-width:calc(736px + 2 * 16px);}/*!sc*/
data-styled.g57[id="Spacing__WidthWrapper-sc-1sl48mq-1"]{content:"hzIikw,"}/*!sc*/
.kNPaXV{display:grid;grid-gap:8px;justify-items:center;width:100%;}/*!sc*/
data-styled.g58[id="Image__Figure-sc-v6pdfp-0"]{content:"kNPaXV,"}/*!sc*/
.gwIYwH{max-width:100%;max-height:700px;min-height:300px;}/*!sc*/
.gwIYwH img{box-shadow:inset 0px 0px 1px 1px rgba(0,0,0,0.1);}/*!sc*/
data-styled.g60[id="Image__StyledGatsbyImage-sc-v6pdfp-2"]{content:"gwIYwH,"}/*!sc*/
.sslfY{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:12px;line-height:16px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;color:var(--color-grey-700);}/*!sc*/
@media (min-width:564px){.sslfY{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:14px;line-height:16px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;}}/*!sc*/
data-styled.g61[id="Image__FigCaption-sc-v6pdfp-3"]{content:"sslfY,"}/*!sc*/
.jVnBRz{width:100%;display:grid;justify-items:center;grid-gap:24px;}/*!sc*/
data-styled.g62[id="Intro__Wrapper-sc-132g0g6-0"]{content:"jVnBRz,"}/*!sc*/
.gQJmPv{display:grid;grid-gap:24px;}/*!sc*/
data-styled.g63[id="Intro__Details-sc-132g0g6-1"]{content:"gQJmPv,"}/*!sc*/
.bMLEnJ{width:100%;display:grid;justify-items:center;grid-gap:8px;}/*!sc*/
data-styled.g64[id="Intro__Cover-sc-132g0g6-2"]{content:"bMLEnJ,"}/*!sc*/
.eTnLxY{padding:0 16px;background-color:var(--color-grey-100);border-left:8px solid var(--color-primary-300);}/*!sc*/
data-styled.g65[id="Text__BlockquoteStyle-sc-pne2eg-0"]{content:"eTnLxY,"}/*!sc*/
.gatsby-highlight{width:100%;padding:0;}/*!sc*/
@media (min-width:calc(920px + 2 * 16px)){.gatsby-highlight{padding:0 16px;max-width:calc(920px + 2 * 16px);}}/*!sc*/
data-styled.g66[id="sc-global-kKEzdQ1"]{content:"sc-global-kKEzdQ1,"}/*!sc*/
.jhqbwH{font-family:"Fira Code",monospace !important;font-size:14px !important;line-height:21px !important;width:100%;max-width:100%;margin:0 !important;border-radius:0px !important;}/*!sc*/
@media (min-width:564px){.jhqbwH{font-family:"Fira Code",monospace !important;font-size:16px !important;line-height:24px !important;}}/*!sc*/
@media (min-width:calc(920px + 2 * 16px)){.jhqbwH{border-radius:6px !important;max-width:calc(920px + 2 * 16px);}}/*!sc*/
data-styled.g67[id="Code__Pre-sc-1hiidew-0"]{content:"jhqbwH,"}/*!sc*/
.eUIYgH{font-family:"Fira Code",monospace !important;font-size:14px !important;line-height:21px !important;width:100%;max-width:100%;}/*!sc*/
@media (min-width:564px){.eUIYgH{font-family:"Fira Code",monospace !important;font-size:16px !important;line-height:24px !important;}}/*!sc*/
data-styled.g68[id="Code__StyledCode-sc-1hiidew-1"]{content:"eUIYgH,"}/*!sc*/
.jTtpAZ{padding-left:40px;}/*!sc*/
data-styled.g75[id="List__UnorderedStyle-sc-1rx07kj-0"]{content:"jTtpAZ,"}/*!sc*/
.dQWCGO{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:16px;line-height:24px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}/*!sc*/
@media (min-width:564px){.dQWCGO{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:18px;line-height:28px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;}}/*!sc*/
.dQWCGO > .Spacing__ExtendingWrapper-sc-1sl48mq-0{padding-left:0;}/*!sc*/
.dQWCGO > *{margin-bottom:12px;}/*!sc*/
.dQWCGO::marker{color:var(--color-grey-500);}/*!sc*/
.dQWCGO:hover::marker{color:var(--color-primary-100);}/*!sc*/
data-styled.g77[id="List__Item-sc-1rx07kj-2"]{content:"dQWCGO,"}/*!sc*/
.bIVzKL{width:100%;border:0;border-top:1px solid var(--color-grey-300);}/*!sc*/
data-styled.g78[id="Separator-sc-vmi8al-0"]{content:"bIVzKL,"}/*!sc*/
.gatsby-resp-image-figure{width:100%;}/*!sc*/
@media (min-width:calc(736px + 2 * 16px)){.gatsby-resp-image-figure{padding:0 16px;max-width:calc(736px + 2 * 16px);}.gatsby-resp-image-figure > img{border-radius:2px;}}/*!sc*/
.gatsby-resp-image-figcaption{text-align:center;margin-top:8px;font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:12px;line-height:16px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;color:var(--color-grey-700);}/*!sc*/
@media (min-width:564px){.gatsby-resp-image-figcaption{font-family:"Fira Sans",sans-serif;font-style:normal;font-weight:normal;font-size:14px;line-height:16px;-webkit-letter-spacing:0.4px;-moz-letter-spacing:0.4px;-ms-letter-spacing:0.4px;letter-spacing:0.4px;}}/*!sc*/
data-styled.g79[id="sc-global-hPHbpt1"]{content:"sc-global-hPHbpt1,"}/*!sc*/
.kczFeb{width:100%;max-width:100%;overflow-x:auto;}/*!sc*/
.kczFeb > *{margin-bottom:24px;margin-right:auto;margin-left:auto;}/*!sc*/
.kczFeb > *:not(figure,div,hr){width:100%;padding:0 16px;max-width:calc(736px + 2 * 16px);}/*!sc*/
.kczFeb > h1,.kczFeb h2,.kczFeb h3,.kczFeb h4,.kczFeb h5,.kczFeb h6{margin-top:36px;margin-bottom:16px;}/*!sc*/
.kczFeb > *:last-child{margin-bottom:0px;}/*!sc*/
data-styled.g80[id="Render__Wrapper-sc-vfulom-0"]{content:"kczFeb,"}/*!sc*/
.dLLVsH{display:grid;grid-auto-flow:row;grid-gap:8px;}/*!sc*/
data-styled.g82[id="styles__Wrapper-sc-wtfdzw-0"]{content:"dLLVsH,"}/*!sc*/
.jcfxca{display:grid;grid-auto-flow:column;grid-gap:24px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/
@media (max-width:404px){.jcfxca{grid-auto-flow:row;grid-gap:8px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;justify-items:center;}}/*!sc*/
data-styled.g83[id="styles__LinkWrapper-sc-wtfdzw-1"]{content:"jcfxca,"}/*!sc*/
.klfMUO{color:var(--color-grey-600);text-transform:uppercase;}/*!sc*/
data-styled.g84[id="styles__Label-sc-wtfdzw-2"]{content:"klfMUO,"}/*!sc*/
.bdXlSx{display:grid;grid-auto-flow:column;grid-gap:12px;}/*!sc*/
.bdXlSx svg{color:var(--color-grey-700);}/*!sc*/
.bdXlSx svg:hover{color:var(--color-primary);}/*!sc*/
data-styled.g85[id="styles__LinkGrid-sc-wtfdzw-3"]{content:"bdXlSx,"}/*!sc*/
.buJfop{cursor:pointer;}/*!sc*/
data-styled.g86[id="styles__LinkButton-sc-wtfdzw-4"]{content:"buJfop,"}/*!sc*/
.dnuyCI{width:100%;display:grid;grid-gap:24px;justify-items:center;}/*!sc*/
data-styled.g87[id="Article__Wrapper-sc-1wer3ng-0"]{content:"dnuyCI,"}/*!sc*/
.cINefJ{padding:0 16px;justify-self:center;display:grid;justify-items:center;}/*!sc*/
data-styled.g88[id="styles__Wrapper-sc-1j7bgew-0"]{content:"cINefJ,"}/*!sc*/
.fMFOTK{display:grid;grid-auto-flow:column;grid-gap:32px;justify-items:center;}/*!sc*/
@media (max-width:500px){.fMFOTK{grid-auto-flow:row;}}/*!sc*/
data-styled.g89[id="styles__Main-sc-1j7bgew-1"]{content:"fMFOTK,"}/*!sc*/
.fKlCeM{display:grid;grid-gap:16px;-webkit-align-content:flex-start;-ms-flex-line-pack:start;align-content:flex-start;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}/*!sc*/
@media (max-width:500px){.fKlCeM{grid-auto-flow:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}/*!sc*/
data-styled.g90[id="styles__Info-sc-1j7bgew-2"]{content:"fKlCeM,"}/*!sc*/
.kVGYMk{margin-top:8px;display:grid;grid-auto-flow:column;grid-gap:24px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;}/*!sc*/
@media (max-width:500px){.kVGYMk{margin-top:32px;grid-auto-flow:row;grid-gap:8px;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;justify-items:center;}}/*!sc*/
data-styled.g91[id="styles__Contact-sc-1j7bgew-3"]{content:"kVGYMk,"}/*!sc*/
.dMfpcP{width:128px;height:128px;border-radius:50%;overflow:hidden;}/*!sc*/
data-styled.g92[id="styles__Avatar-sc-1j7bgew-4"]{content:"dMfpcP,"}/*!sc*/
.fcQYzl{color:var(--color-grey-600);line-height:100%;}/*!sc*/
data-styled.g93[id="styles__ShareLabel-sc-1j7bgew-5"]{content:"fcQYzl,"}/*!sc*/
.ktJMSx{color:var(--color-primary);}/*!sc*/
.ktJMSx::before{content:"by ";color:var(--color-grey-300);}/*!sc*/
data-styled.g94[id="styles__AuthorName-sc-1j7bgew-6"]{content:"ktJMSx,"}/*!sc*/
.szQTJ{width:0;min-width:100%;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;}/*!sc*/
@media (max-width:500px){.szQTJ > p{text-align:justify;}}/*!sc*/
data-styled.g95[id="styles__AboutText-sc-1j7bgew-7"]{content:"szQTJ,"}/*!sc*/
.kVEIfd{grid-gap:12px;}/*!sc*/
data-styled.g96[id="styles__TightUserLinks-sc-1j7bgew-8"]{content:"kVEIfd,"}/*!sc*/
.emthwx{margin-top:8px;}/*!sc*/
data-styled.g97[id="styles__Separator-sc-1j7bgew-9"]{content:"emthwx,"}/*!sc*/
.hZSFY{display:grid;grid-gap:40px;justify-items:center;}/*!sc*/
data-styled.g98[id="RelatedPosts__Wrapper-sc-1ga516s-0"]{content:"hZSFY,"}/*!sc*/
.kudTDK{text-transform:uppercase;color:var(--color-grey-700);}/*!sc*/
data-styled.g99[id="RelatedPosts__Label-sc-1ga516s-1"]{content:"kudTDK,"}/*!sc*/
.iPcdba{display:grid;grid-gap:60px;}/*!sc*/
data-styled.g100[id="post__Wrapper-sc-3xaw55-0"]{content:"iPcdba,"}/*!sc*/
</style><title data-react-helmet="true">Interpreting ML Models Part 2</title><link data-react-helmet="true" href="https://fonts.googleapis.com/css2?family=Alfa+Slab+One&amp;family=Fira+Sans:ital,wght@0,400;0,500;1,400&amp;family=Fira+Code:wght@500&amp;display=swap" rel="stylesheet"/><link data-react-helmet="true" rel="shortcut icon" href="/logos/logo-1024.png"/><meta data-react-helmet="true" name="description" content="Second part in understanding ML Models."/><meta data-react-helmet="true" name="image" content="/static/b57872d67fc00d945468ce891f38f187/cover_6.jpeg"/><meta data-react-helmet="true" property="og:title" content="Interpreting ML Models Part 2"/><meta data-react-helmet="true" property="og:type" content="article"/><meta data-react-helmet="true" property="og:url" content="https://ashishthanki.github.io/interpreting-ml-models-part-2"/><meta data-react-helmet="true" property="og:image" content="/static/b57872d67fc00d945468ce891f38f187/cover_6.jpeg"/><meta data-react-helmet="true" property="og:image:alt" content="A view of mountains."/><meta data-react-helmet="true" property="og:site_name" content="Ashish__Thanki"/><meta data-react-helmet="true" property="og:description" content="Second part in understanding ML Models."/><meta data-react-helmet="true" property="article:published_time" content="2021-09-26T00:00:00.000Z"/><meta data-react-helmet="true" property="article:modified_time" content="2021-09-26T00:00:00.000Z"/><meta data-react-helmet="true" property="article:author" content="http://examples.opengraphprotocol.us/profile.html"/><meta data-react-helmet="true" property="profile:first_name" content="Ashish"/><meta data-react-helmet="true" property="profile:last_name" content="Thanki"/><meta data-react-helmet="true" property="profile:username" content="AshishThanki"/><meta data-react-helmet="true" property="article:section" content="Interpretability"/><meta data-react-helmet="true" property="article:tag" content="Machine Learning"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:title" content="Interpreting ML Models Part 2"/><meta data-react-helmet="true" name="twitter:description" content="Second part in understanding ML Models."/><meta data-react-helmet="true" name="twitter:image" content="/static/b57872d67fc00d945468ce891f38f187/cover_6.jpeg"/><meta data-react-helmet="true" name="twitter:image:alt" content="A view of mountains."/><meta data-react-helmet="true" name="twitter:creator" content="Ashish__thanki"/><meta data-react-helmet="true" name="twitter:site" content="ashish__thanki"/><script data-react-helmet="true" type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","url":"https://www.fospha.com","name":"Ashish Thanki","description":"Direct-To-Consumer brands use Fospha’s measurement platform to achieve rapid and sustainable growth through customer acquisition and retention.","logo":"Ahttps://www.blenheimchalcot.com/wp-content/uploads/2018/07/Fospha_Logos_RGB_Marketing_Fospha_Marketing.png"}</script><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","image":"/static/b57872d67fc00d945468ce891f38f187/cover_6.jpeg","url":"https://ashishthanki.github.io/interpreting-ml-models-part-2","headline":"Interpreting ML Models Part 2","name":"Interpreting ML Models Part 2","description":"Second part in understanding ML Models.","dateCreated":"2021-09-26T00:00:00.000Z","datePublished":"2021-09-26T00:00:00.000Z","dateModified":"2021-09-26T00:00:00.000Z","author":{"@type":"Person","givenName":"Ashish","familyName":"Thanki","email":"ashish_thanki@hotmail.com","address":"London United Kingdom"},"creator":{"@type":"Person","givenName":"Ashish","familyName":"Thanki","email":"ashish_thanki@hotmail.com","address":"London United Kingdom"},"publisher":{"@context":"https://schema.org","@type":"Organization","url":"https://www.fospha.com","name":"Ashish Thanki","description":"Direct-To-Consumer brands use Fospha’s measurement platform to achieve rapid and sustainable growth through customer acquisition and retention.","logo":"Ahttps://www.blenheimchalcot.com/wp-content/uploads/2018/07/Fospha_Logos_RGB_Marketing_Fospha_Marketing.png"},"mainEntityOfPage":"True","keywords":["Machine Learning"],"articleSection":"Interpretability","articleBody":"\ntitle: \"Interpreting ML Models Part 2\"\ncover: images/cover_6.jpeg\ncoverAlt: \"A view of mountains.\"\ndescription: \"Second part in understanding ML Models.\"\ndatePublished: \"2021-09-26\"\ndateModified: \"2021-09-26\"\ncategory: \"Interpretability\"\ntags:\n  Machine Learning\n\nIntroduction\n\nExplaining features and interpreting your models has taken a sharp rise in Europe. Partly because of new laws and regulatory measures being taken, such as GDPR and the EU’s \"Right to Explanations\", alongside the rise in interest in applying machine learning. This has mandated data scientists to explain why a model has given a certain prediction. For example, institutions with highly sensitive data (i.e. personal data), that have models that output a potentially life changing decision would mandate regulations and require the data scientists to explain the decision that had been made. Hence, this blog post on model interpreting.\n\nThis blog is part 2 of a 2 part series where this blog covers SHAP and LIME. The first part of this series covered  Feature Importance, Permutation Importance and Partial Dependence Plots, I recommend reading that first before this blog post, check it out here.\n\nSummary of Permutation Importance and Partial Dependence\n\nBy using Permutation Importance you can identify which features are important and then by using Partial Dependence plots you understand how the prediction varies based on the changes to individual features. But what if you want to know the impact each feature has on one specific prediction. This is where SHAP and LIME comes in, by using these techniques you will then be able to explain why a certain predicted value was reached and have a better understanding of your machine learning models.\n\nSHapley Additive exPlanations (SHAP)\n\nSHapley Additive exPlanations (SHAP) is a game theory approach to explain the output of any machine learning model. SHAP can break down a prediction to show the impact of each feature. The SHAP explanation requires us to compute the shapley values from coalition game theory.\n\n> The shapley value is a solution for computing feature contributions for single predictions for any machine learning model.\n\nA shapley value is based on game theory. Each feature represents a “player” in the game and the prediction represents the pay-out. The distribution of the pay-outs are shapley values. The shapley values is a method that assigns payouts to features depending on their contribution to the model's prediction. The features cooperate in a coalition and receive a certain payout because of this corporation. The shapley value is the average marginal contribution of a feature's value when making predictions.\n\n...If that didn't make sense then I would suggest learning a bit more about Game Theory, once you do that replace the word “features” with “players” in the above explanation and it should click.\n\nSHAP values. Example SHAP value plot. Further explanation is provided below.\n\nWhen a prediction is made, the summation of an instance's SHAP values for each feature explains why the prediction was different from the baseline. The baseline is the average shapley value for all predictions. If the SHAP value is large for a given feature than the contribution to the model's prediction is large.\n\nWARNING: The shapley value is not the prediction if we had removed a feature from the dataset. It is the average contribution of a feature value to a prediction across all possible coalitions.\n\nHowever, the downside of calculating shapley values is the computational load. The number of coalitions can grow exponentially based on the number of features, and the number of iterations can contribute a large amount to the computational time. We handle both of these by taking a sample of coalitions and limiting the number of iterations both of which contribute towards the variance in the final shapley value. In effect, when we use Python libraries such as shap we are using estimations.\n\nEstimating SHAP\n\nThis leads very nicely to SHAP estimations. SHAP uses efficient methods to estimate the shapley values for a given machine learning model. There are 2 popular estimations TreeSHAP and KernelSHAP.\n\nTreeSHAP estimates SHAP values for models that are decision tree based and,\nKernelSHAP is inspired by local surrogate models and can estimate other types of model but has its disadvantages.\n\nComputational complexity from KernelSHAP to TreeSHAP is reduced significantly, $O(TL^2M)$ to $O(TLD^2)$.\n\nThe downside to KernalSHAP is that the kernel may be increase weightings for samples that are unrealistic. This is a common problem for permutation based interpretation methods. For example, changing either feature when a set of features are correlated, i.e. age and resting heart rate, could produce samples that are unrealistic. We would not expect a low resting heart rate high when the age is low. This will result in some features dependence being ignored.\n\nTypes of SHAP plots\n\nThe SHAP library is able to produce all the plots described below. It also has many other visualizations which are comparable to permutation importance and partial dependence plots.\n\n1. Force Plots\n\nForce Plot example. A force plot example.\n\nA force plot shows, for a single instance, which features contribute towards pushing the model to a certain value. As you can see above the the feature values shown in blue are reducing the prediction value while the feature vales shown in red are increasing the prediction.\n\n2. Summary Plots\n\nSummary Plots. Taken from research paper on interpreting machine learning models of biological age.\n\nWe can combine multiple force plots together and then rotate it to have a summary across the entire dataset. Summary plots show many useful insights into all the features, each dot shows three characteristics:\n\nVertical location is the feature it is representing.\nColor shows the magnitude of the feature value for that feature.\nHorizontal location is the effect of that value causing a higher or lower prediction.\n\nIn the plots you can gain a strong intuition on how a decision was made by your black box model. Some features will generally have no input in the prediction until a certain feature value, whereas some features will have zero input and is ignored entirely by the model.\n\n3. SHAP Dependence Plots\n\nSHAP Dependence Plots. SHAP Dependence plot showing the affects of feature magnitude (age) on predicted values (marital status) and SHAP value.\n\nThe SHAP dependence plots are used to identify how a feature magnitude affects the predicted value. You can then observe the general pattern (or not) on how the feature affects prediction.\n\nMinimal Trend SHAP Dependence plot. SHAP Dependence plot showing a small trend between ball possession and goals scored. As you can see from the data, some teams record a 70% ball possession but fall short of scoring goals - which is what we would expect.\n\nConversely, if there was large standard deviation, with no apparent pattern, then we can assume that other features are interacting with this feature. Similarly, if a feature has arbitrary values then it would lead to arbitrary predictions. For example, a binary feature within the dataset of value 0 could make the feature under investigation more relevant but when the value is 1 makes the feature irrelevant.\n\nIf points follow a trend but are widely spread out (in both SHAP and feature magnitude) then we can assume the permutation importance is high because the prediction is sensitive to magnitude. However, a few outliers can ruin this assumption. It is worth producing Force plots for those points to understand why they do not follow the trend.\n\nLocal Interpretable Model-Agnostic Explanations - LIME\n\nLets reflect back on what we have learnt so far. Using PI and PD have their limitations, as discussed within the Part 1 blog. SHAP are subject to incorrect interpretation because the observations from multiple plots have to be used in order to make intuitions about the features. All these interpretation methodologies work really well with simple models but can be difficult to use, and interpret, when using it on complex models. These methods depend highly on model inference time and could take a lot of computational resources. This is where LIME (Local Interpretable Model-Agnostic Explanations) comes in.\n\nLIME is a simple method that provides human-understandable model interpretation. It produces a local linear interpretable machine learning model which results in a reduced computational complexity. LIME is able to explain any complex model's prediction and allow logical intuitions about the features.\n\nLIME Titanic Example. Example of LIME interpreting a XGM model on predicting whether a passenger survived the Titanic. The model has realised that sex is an important feature.\n\nThe lime' library was created by the originators of LIME. It has a simple API that allows us to gain explanations about the model no matter how complex. You can visualize the output of the Explainer objects to understand how each of the features influences the prediction - the Explainer object is within the Explanation` module.\n\nPython Libraries\n\nBelow are relevant links to Python libraries, and code snippets, that have been discussed throughout the 2 blog posts.\n\nPDPbox helps visualize the partial dependence plots.\neli5 helps debug and explain machine learning models, and helps us visualize permutation importance.\nshap allows us to interpret models using SHAP values.\nlime allows us to use local explanations (LIME) to interpret models.\n\npdpbox\n\nCalculate and show partial dependence plot:\n\nfrom matplotlib import pyplot as plt\nfrom pdpbox import pdp, getdataset, infoplots\n\nCreate the data that we will plot\npdpgoals = pdp.pdpisolate(model=mymodel, dataset=X, modelfeatures=feature_names, feature='Goal Scored')\n\nplot it\npdp.pdpplot(pdpgoals, 'Goal Scored')\nplt.show()\n\neli5\n\nCalculate and show permutation importance:\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(mymodel, randomstate=1).fit(X, y)\neli5.showweights(perm, featurenames = X.columns.tolist())\n\nshap\n\nCalculate and show SHAP Values for One Prediction (i.e Force plot):\n\nimport shap  # package used to calculate Shap values\n\nuse 1 row of data here. Could use multiple rows if desired\ndataforprediction = X.iloc[0,:]\n\nCreate object that can calculate shap values\nexplainer = shap.TreeExplainer(my_model)\nshapvalues = explainer.shapvalues(dataforprediction)\nshap.initjs()\nshap.forceplot(explainer.expectedvalue[0], shapvalues[0], datafor_prediction)\n\nlime\n\nCalculate and show feature importance plot using LIME:\n\nfrom lime.lime_text import LimeTextExplainer # import Explainer object\nexplainer = LimeTextExplainer(classnames=classnames)\n\ncreate explainer object with single instance and a classifier function\nexp = explainer.explaininstance(X[0], pipeline.predictproba, num_features=6)\n\nnote: you should check how this local linear model compares\nto your original model.\nIf the linear model is not representative of original model\nfor that region then it is not wise to use that linear\nmodel to make conclusions about features.\n\nexp.as_list() # list of weighted features\nexp.aspyplotfigure() # explanations return as a plot\n\nWhen to use each?\n\nUse permutation importance if you require a succinct model summary. Summarizing importance of all features in a global sense.\n\nUse partial plot to understand individual features or relationships between features (i.e. using 2D partial dependence plots). Summarizing the importance of a single feature and its affect on the prediction in a global sense.\n\nUse SHAP when you need to show the impact of each feature for a given row. If you require a global sense of a feature you can also use this too.\n\nUse LIME when computational load is large for the above methods or if the outputs are ambiguous. This will allow you to understand your model from local points within you dataset.\n\nShapley values are the only method that provides contrastive explanations, where it has the potential to compare predictions to a subset of data, or a single data point. Using SHAP provides a consistent approach for both global and local explanations. Although, it can be easily misinterpreted. Meanwhile, methods like LIME are very easy to interpret. However, the premise that there is a local linear relationship might not always be true.\n\nConclusion\n\nMany methods can help us identify which features to focus on and then measure individual feature importance. However, interpreting these values are crucial for data scientists to avoid introducing biases into the prediction. SHAP is widely considered the optimal solution due to its Game Theory approach, however, all interpretation methods should be explored before being confirmed by a domain expert. SHAP has the potential to be misinterpreted and can hide biases.\n\nBeing able to use machine learning to predict the probability of a patient having cancer is a great asset to have for any health care professional. However, informing a patient, “you have a high probability of being diagnosed cancer” is not enough. Interpreting a machine learning model's prediction can break down which features a patient should focus on in order to reduce their risk.\n\nModel interpretation is not going away. Law makers will demand data scientists to interpret their models and these tools are just the start of an expanding specialism within data science. Personally, I am excited by tools like LIME, that are trying solve the limitations of its predecessors while providing even more insight about our machine learning models.\n\nFurther reading:\n\nThings to avoid when interpreting models - highly recommend reading this paper by Standford\nInterpretable Machine Learning Book by Christoph Molnar\nPyData Talk on Interpreting models with LIME and SHAPE\nPyData Talk on SHAP Values\nSHAP Dependence plots Notebook\nA good example of a researchgate paper interpreting SHAP values to provide conclusions on Biological age.\n"}</script><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){if(void 0===e.target.dataset.mainImage)return;if(void 0===e.target.dataset.gatsbyImageSsr)return;const t=e.target;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="preconnect" href="https://www.googletagmanager.com"/><link rel="dns-prefetch" href="https://www.googletagmanager.com"/><link rel="sitemap" type="application/xml" href="/sitemap/sitemap-index.xml"/><link rel="icon" href="/favicon-32x32.png" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#000"/><link rel="alternate" type="application/rss+xml" title="test" href="/test"/><link as="script" rel="preload" href="/webpack-runtime-f5df9ae31cf3fa65ae1f.js"/><link as="script" rel="preload" href="/framework-fd08d525545552f00d3a.js"/><link as="script" rel="preload" href="/532a2f07-bee56c167ebe722e4032.js"/><link as="script" rel="preload" href="/app-f22f5a19420f4ca20847.js"/><link as="script" rel="preload" href="/1d2d7d1d436f49e73dd3293234cd23312ebe1944-2e06c528b8e91ae27611.js"/><link as="script" rel="preload" href="/3a5981d123eec27129dd35f297abe92aafc96141-111e96cba930f7ce0d45.js"/><link as="script" rel="preload" href="/component---themes-advanced-src-templates-post-query-ts-90b9d532d7784b7497f4.js"/><link as="fetch" rel="preload" href="/page-data/interpreting-ml-models-part-2/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3661114550.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="layouts__LayoutGrid-sc-wfe7y9-0 hYSJmR"><div class="LayoutWidthContainer-sc-obprvr-0 fwyrVH"><header class="style__Wrapper-sc-axaxo7-1 hA-dGla"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ style__HomeButton-sc-axaxo7-0 wTDnd" href="/"><svg width="36" height="36" id="Isolation_Mode" data-name="Isolation Mode" viewBox="0 0 2048 2048"><defs><style>.cls-1{fill:#1a1a1a;}.cls-2{fill:#d83850;}</style></defs><title>Colored - Simple</title><path class="cls-1" d="M2016.32423,992.95364,1852.38464,950.673a12.48342,12.48342,0,0,1-9.1156-9.72738A761.71552,761.71552,0,0,0,1727.7054,662.11777a12.47565,12.47565,0,0,1-.42566-13.32014l86.06342-145.8836a10.69808,10.69808,0,0,0-2.02894-12.88417L1690.46179,369.17819a10.69627,10.69627,0,0,0-12.88341-2.02894l-145.88694,86.0648a12.47,12.47,0,0,1-13.31439-.42531,763.90851,763.90851,0,0,0-128.64824-69.60922,12.574,12.574,0,0,0-16.85117,15.407l54.919,171.70786a12.38622,12.38622,0,0,0,4.93711,6.52555c165.278,110.33124,274.16649,298.50186,274.16649,512.13416a613.87732,613.87732,0,0,1-40.23128,219.24568,12.38261,12.38261,0,0,0-.23817,8.19727l54.814,171.38a12.56235,12.56235,0,0,0,22.62778,2.81034,761.016,761.016,0,0,0,99.39582-253.62233,12.48913,12.48913,0,0,1,9.11956-9.73113l163.93627-42.27944A10.69794,10.69794,0,0,0,2024,1174.40935V1003.49882A10.698,10.698,0,0,0,2016.32423,992.95364Z"></path><path class="cls-1" d="M31.67577,992.95364,195.61536,950.673a12.48342,12.48342,0,0,0,9.1156-9.72738A761.71552,761.71552,0,0,1,320.2946,662.11777a12.47565,12.47565,0,0,0,.42566-13.32014L234.65684,502.914a10.69808,10.69808,0,0,1,2.02894-12.88417L357.53821,369.17819a10.69627,10.69627,0,0,1,12.88341-2.02894l145.88694,86.0648a12.47,12.47,0,0,0,13.31439-.42531,763.90851,763.90851,0,0,1,128.64824-69.60922,12.574,12.574,0,0,1,16.85117,15.407l-54.919,171.70786a12.38622,12.38622,0,0,1-4.93711,6.52555c-165.278,110.33124-274.16649,298.50186-274.16649,512.13416A613.87732,613.87732,0,0,0,381.331,1308.19977a12.38261,12.38261,0,0,1,.23817,8.19727l-54.814,171.38a12.56235,12.56235,0,0,1-22.62778,2.81034A761.016,761.016,0,0,1,204.7316,1236.9651a12.48913,12.48913,0,0,0-9.11956-9.73113L31.67577,1184.95453A10.69794,10.69794,0,0,1,24,1174.40935V1003.49882A10.698,10.698,0,0,1,31.67577,992.95364Z"></path><path class="cls-2" d="M1393.934,1595.61448h220.41689a47.03461,47.03461,0,0,0,45.4344-33.43649,43.6634,43.6634,0,0,0-.31789-26.288l-.25761-.80785-64.2669-200.93607L1358.95454,596.31668l-64.38342-201.29933-59.22279-185.16753c-6.15369-19.23618-24.43326-32.33887-45.1182-32.33887H864.64992c-20.68494,0-38.96619,13.10269-45.1182,32.33887l-57.5889,180.05489-62.9115,196.7004-244.443,764.26454-59.17564,185.02029c-.14632.45688-.21619.91216-.34634,1.369-8.36106,29.1839,14.08994,58.3555,45.46285,58.3555H676.9573c21.5726,0,40.40561-14.23087,45.77115-34.58311l79.79761-302.68495H1240.7733l79.25681,302.61441c5.33943,20.38742,24.18911,34.65365,45.78933,34.65365H1393.934M868.44235,1008.31274l34.4437-130.64916c30.76912-118.09991,64.03084-253.22846,94.90705-381.68541,5.79338-24.1019,11.51132-47.99544,17.104-71.4688a5.65106,5.65106,0,0,1,10.93312.01221c5.50074,23.44431,11.24327,47.30864,17.12857,71.38,31.40491,128.47993,67.33735,263.63761,98.11389,381.762l34.21673,130.64916Z"></path></svg><p class="style__SiteTitle-sc-axaxo7-3 jWrjvl">Ashish Thanki</p></a><nav class="style__NavGrid-sc-axaxo7-2 jAhXWb"><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt style__NavButton-sc-axaxo7-4 cbaIXU" href="/">Posts</a><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt style__NavButton-sc-axaxo7-4 cbaIXU" href="/about">About</a></nav></header></div><div class="post__Wrapper-sc-3xaw55-0 iPcdba"><main class="Article__Wrapper-sc-1wer3ng-0 dnuyCI"><section class="Intro__Wrapper-sc-132g0g6-0 jVnBRz"><div class="Spacing__WidthWrapper-sc-1sl48mq-1 hzIikw"><div class="Intro__Details-sc-132g0g6-1 gQJmPv"><h1 class="Primitives__H1-sc-1kfaxvk-0 hdUndc">Interpreting ML Models Part 2</h1><p class="Primitives__Body-sc-1kfaxvk-6 eKNIHW">Introduction Explaining features and interpreting your models has taken a sharp rise in Europe. Partly because of new laws and regulatory…</p></div></div><div class="Intro__Cover-sc-132g0g6-2 bMLEnJ"><div class="Spacing__WidthWrapper-sc-1sl48mq-1 hzIikw"><div class="styles__Wrapper-sc-evad3c-5 dofHQH"><div class="styles__InfoGrid-sc-evad3c-3 duPBEk"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ styles__CategoryLink-sc-evad3c-1 eyoDpl" href="/category/Interpretability">Interpretability</a><p class="Primitives__Caption-sc-1kfaxvk-7 styles__Caption-sc-evad3c-2 ksrFqo kToWai"> ⋅ Sep 26, 2021 ⋅ 7 min read</p></div><div class="styles__TagGrid-sc-evad3c-4 eWUSCD"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ styles__TagLink-sc-evad3c-0 coRloj" href="/tag/Machine Learning">Machine Learning</a></div></div></div><figure class="Image__Figure-sc-v6pdfp-0 kNPaXV"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained Image__StyledGatsbyImage-sc-v6pdfp-2 gwIYwH"><div style="max-width:2500px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg height=&#x27;1000&#x27; width=&#x27;2500&#x27; xmlns=&#x27;http://www.w3.org/2000/svg&#x27; version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:transparent;position:absolute;top:0;left:0;bottom:0;right:0" decoding="async" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAGkhnAX/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAEDERMU/9oACAEBAAEFAnM2bUdDP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAABITH/2gAIAQEABj8CjRWYf//EABoQAAICAwAAAAAAAAAAAAAAAAABIVExYbH/2gAIAQEAAT8hzaQ7XSkq4P/aAAwDAQACAAMAAAAQDC//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEUH/2gAIAQMBAT8Q2I//xAAWEQEBAQAAAAAAAAAAAAAAAAABEQD/2gAIAQIBAT8QGl1d/8QAHBABAAICAwEAAAAAAAAAAAAAAQAhEZExUWGx/9oACAEBAAE/EDEe0jSbichdpTUAoMemXyf/2Q==" alt=""/><picture><source type="image/avif" data-srcset="/static/b57872d67fc00d945468ce891f38f187/44552/cover_6.avif 625w,/static/b57872d67fc00d945468ce891f38f187/fdd2c/cover_6.avif 1250w,/static/b57872d67fc00d945468ce891f38f187/d8633/cover_6.avif 2500w" sizes="(min-width: 2500px) 2500px, 100vw"/><source type="image/webp" data-srcset="/static/b57872d67fc00d945468ce891f38f187/a07b5/cover_6.webp 625w,/static/b57872d67fc00d945468ce891f38f187/f1147/cover_6.webp 1250w,/static/b57872d67fc00d945468ce891f38f187/0676d/cover_6.webp 2500w" sizes="(min-width: 2500px) 2500px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 2500px) 2500px, 100vw" decoding="async" loading="lazy" data-src="/static/b57872d67fc00d945468ce891f38f187/ee7c2/cover_6.jpg" data-srcset="/static/b57872d67fc00d945468ce891f38f187/74341/cover_6.jpg 625w,/static/b57872d67fc00d945468ce891f38f187/c98fe/cover_6.jpg 1250w,/static/b57872d67fc00d945468ce891f38f187/ee7c2/cover_6.jpg 2500w" alt="A view of mountains."/></picture><noscript><picture><source type="image/avif" srcSet="/static/b57872d67fc00d945468ce891f38f187/44552/cover_6.avif 625w,/static/b57872d67fc00d945468ce891f38f187/fdd2c/cover_6.avif 1250w,/static/b57872d67fc00d945468ce891f38f187/d8633/cover_6.avif 2500w" sizes="(min-width: 2500px) 2500px, 100vw"/><source type="image/webp" srcSet="/static/b57872d67fc00d945468ce891f38f187/a07b5/cover_6.webp 625w,/static/b57872d67fc00d945468ce891f38f187/f1147/cover_6.webp 1250w,/static/b57872d67fc00d945468ce891f38f187/0676d/cover_6.webp 2500w" sizes="(min-width: 2500px) 2500px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 2500px) 2500px, 100vw" decoding="async" loading="lazy" src="/static/b57872d67fc00d945468ce891f38f187/ee7c2/cover_6.jpg" srcSet="/static/b57872d67fc00d945468ce891f38f187/74341/cover_6.jpg 625w,/static/b57872d67fc00d945468ce891f38f187/c98fe/cover_6.jpg 1250w,/static/b57872d67fc00d945468ce891f38f187/ee7c2/cover_6.jpg 2500w" alt="A view of mountains."/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div><figcaption class="Image__FigCaption-sc-v6pdfp-3 sslfY">A view of mountains.</figcaption></figure></div></section><article class="Render__Wrapper-sc-vfulom-0 kczFeb"><h1 id="introduction" class="Primitives__H1-sc-1kfaxvk-0 hdUndc"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#introduction">Introduction<!-- --> </a></h1><p>Explaining features and interpreting your models has taken a sharp rise in Europe. Partly because of new laws and regulatory measures being taken, such as GDPR and the EU’s &quot;<a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://en.wikipedia.org/wiki/Right_to_explanation">Right to Explanations</a>&quot;, alongside the rise in interest in applying machine learning. This has mandated data scientists to explain why a model has given a certain prediction. For example, institutions with highly sensitive data (i.e. personal data), that have models that output a potentially life changing decision would mandate regulations and require the data scientists to explain the decision that had been made. Hence, this blog post on model interpreting.</p><p>This blog is part 2 of a 2 part series where this blog covers SHAP and LIME. The first part of this series covered  Feature Importance, Permutation Importance and Partial Dependence Plots, I recommend reading that first before this blog post, check it out <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="./interpreting-ml-models">here</a>.</p><h2 id="summary-of-permutation-importance-and-partial-dependence" class="Primitives__H2-sc-1kfaxvk-1 hTdBcY"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#summary-of-permutation-importance-and-partial-dependence">Summary of Permutation Importance and Partial Dependence<!-- --> </a></h2><p>By using Permutation Importance you can identify which features are important and then by using Partial Dependence plots you understand how the prediction varies based on the changes to individual features. But what if you want to know the <em>impact each feature has</em> on one specific prediction. This is where SHAP and LIME comes in, by using these techniques you will then be able to explain why a certain predicted value was reached and have a better understanding of your machine learning models.</p><h2 id="s-hapley-additive-ex-planations-shap" class="Primitives__H2-sc-1kfaxvk-1 hTdBcY"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#s-hapley-additive-ex-planations-shap">SHapley Additive exPlanations (SHAP)<!-- --> </a></h2><p>SHapley Additive exPlanations (SHAP) is a game theory approach to explain the output of any machine learning model. SHAP can break down a prediction to show the impact of each feature. The SHAP explanation requires us to compute the shapley values from coalition game theory.</p><div class="Spacing__ExtendingWrapper-sc-1sl48mq-0 cHsvLz"><blockquote class="Text__BlockquoteStyle-sc-pne2eg-0 eTnLxY"><p>The shapley value is a solution for computing feature contributions for single predictions for any machine learning model.</p></blockquote></div><p>A shapley value is based on game theory. Each feature represents a “player” in the game and the prediction represents the pay-out. The distribution of the pay-outs are shapley values. The shapley values is a method that assigns payouts to features depending on their contribution to the model&#x27;s prediction. The features cooperate in a coalition and receive a certain payout because of this corporation. The shapley value is the average marginal contribution of a feature&#x27;s value when making predictions. </p><p>...If that didn&#x27;t make sense then I would suggest learning a bit more about Game Theory, once you do that replace the word “features” with “players” in the above explanation and it should click.</p><figure class="gatsby-resp-image-figure">
    <span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:768px">
      <a class="gatsby-resp-image-link" href="/static/a4332a312ce6528d6747f631a9471414/8079d/SHAP_values.png" target="_blank" rel="noopener" style="display:block">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:71.35416666666666%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXElEQVQoz52Q7UvCUBTG9/9DVBQSJWUv9KEvYWmgFkNprD74kjFnmeZGIFIqbdPtvpxzYjPDrIV0eLj3ci7Pee79KUREgCThFwFKirsJfQrFFBL5nIFgFF8Kk4J1e4FaY5oRlOr82gjUWlC6F8V6T70rPo60tqs/u3rH0Tqe3nFuu57Wdp76Y8FZlKybtJ2jZJ52C5S6or1LTOZp62J4cnNUGafK7n7ZPax6BxXvuOZlmxO17bfeePRsjD78r4qSp/55bIAEgADhPpOcrRJCx1/Alk7+RnkuK07T3EUzIswuYguRc+75ETAuhSTkUgIgR2CvI96w4OFFNCzZtIVpi4YlDEuYtjRtblhg2k6t5bke40wBdwIDBwbv0B9CbwiFKqylYTMD62ehNjOQyMLGedhMZGE1DSuncifHfQ6ICvmcxgH57PPA5FKslqWNM0I/cCjhjAV9zcbFqIXmB7/jI7/9FAskAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img src="/static/a4332a312ce6528d6747f631a9471414/e5715/SHAP_values.png" alt="SHAP values. Example SHAP value plot. Further explanation is provided below." title="SHAP values. Example SHAP value plot. Further explanation is provided below." srcSet="/static/a4332a312ce6528d6747f631a9471414/8514f/SHAP_values.png 192w,/static/a4332a312ce6528d6747f631a9471414/804b2/SHAP_values.png 384w,/static/a4332a312ce6528d6747f631a9471414/e5715/SHAP_values.png 768w,/static/a4332a312ce6528d6747f631a9471414/4ad3a/SHAP_values.png 1152w,/static/a4332a312ce6528d6747f631a9471414/71c1d/SHAP_values.png 1536w,/static/a4332a312ce6528d6747f631a9471414/8079d/SHAP_values.png 2100w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" class="Image-sc-n1k2df-0 cNyHKV gatsby-resp-image-image"/>
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption">SHAP values. Example SHAP value plot. Further explanation is provided below.</figcaption>
  </figure><p>When a prediction is made, the summation of an instance&#x27;s SHAP values for each feature explains why the prediction was different from the baseline. The baseline is the average shapley value for all predictions. If the SHAP value is large for a given feature than the contribution to the model&#x27;s prediction is large. </p><p><strong>WARNING</strong>: The shapley value is not the prediction if we had removed a feature from the dataset. It is the average contribution of a feature value to a prediction across all possible coalitions.</p><p>However, the downside of calculating shapley values is the computational load. The number of coalitions can grow exponentially based on the number of features, and the number of iterations can contribute a large amount to the computational time. We handle both of these by taking a sample of coalitions and limiting the number of iterations both of which contribute towards the variance in the final shapley value. In effect, when we use Python libraries such as <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">shap</code> we are using estimations. </p><h3 id="estimating-shap" class="Primitives__H3-sc-1kfaxvk-2 eEpwqO"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#estimating-shap">Estimating SHAP<!-- --> </a></h3><p>This leads very nicely to SHAP estimations. SHAP uses efficient methods to estimate the shapley values for a given machine learning model. There are 2 popular estimations <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">TreeSHAP</code> and <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">KernelSHAP</code>. </p><div class="Spacing__ExtendingWrapper-sc-1sl48mq-0 cHsvLz"><ul class="List__UnorderedStyle-sc-1rx07kj-0 jTtpAZ"><li class="List__Item-sc-1rx07kj-2 dQWCGO"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">TreeSHAP</code> estimates SHAP values for models that are decision tree based and,</li><li class="List__Item-sc-1rx07kj-2 dQWCGO"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">KernelSHAP</code> is inspired by local surrogate models and can estimate other types of model but has its disadvantages.</li></ul></div><p><em>Computational complexity from <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">KernelSHAP</code> to <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">TreeSHAP</code> is reduced significantly, $O(TL^2M)$ to $O(TLD^2)$.</em></p><p>The downside to <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">KernalSHAP</code> is that the kernel may be increase weightings for samples that are unrealistic. This is a common problem for permutation based interpretation methods. For example, changing either feature when a set of features are correlated, i.e. age and resting heart rate, could produce samples that are unrealistic. We would not expect a low resting heart rate high when the age is low. This will result in some features dependence being ignored.  </p><h2 id="types-of-shap-plots" class="Primitives__H2-sc-1kfaxvk-1 hTdBcY"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#types-of-shap-plots">Types of SHAP plots<!-- --> </a></h2><p>The <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://shap.readthedocs.io/en/latest/index.html"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">SHAP</code></a> library is able to produce all the plots described below. It also has many other visualizations which are comparable to permutation importance and partial dependence plots.</p><h3 id="1-force-plots" class="Primitives__H3-sc-1kfaxvk-2 eEpwqO"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#1-force-plots">1. Force Plots<!-- --> </a></h3><figure class="gatsby-resp-image-figure">
    <span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:768px">
      <a class="gatsby-resp-image-link" href="/static/8e73a32ba44d53acc655b844c895e7e4/75a80/force_plot.png" target="_blank" rel="noopener" style="display:block">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:22.395833333333336%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA/0lEQVQY03WMz0oCYRxFf2/QqwVBtGvRLlO0NkG7oFWboD/atKjewGlUkiAoiMqByGhRKWmUxKQWzox+MxnfiXFctGlxOPfexRVARoRaajDRRk8hIqyZwsy6MH8gzG0KiUNhdkOY3hY/V5Bm92Oy47TSK+WOJE+Q28/oZygSKGUErl8OBgMrKFUKKm0ch6ldS2WMYpjKWSqZLYaLe5ZayBbDZNy/Ezt5b3n/fMt8vs6UOuZS/v3orOaewnBVaPccui44X/D4BlcPUHkCu4a+jLOuNuCuMXYTbuqj/f6lj90KsV8DHO8H4EI0VDUMNXga/L/wj8f0iYn2XvSmtTZ/AR07A68DmJPCAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img src="/static/8e73a32ba44d53acc655b844c895e7e4/e5715/force_plot.png" alt="Force Plot example. A force plot example." title="Force Plot example. A force plot example." srcSet="/static/8e73a32ba44d53acc655b844c895e7e4/8514f/force_plot.png 192w,/static/8e73a32ba44d53acc655b844c895e7e4/804b2/force_plot.png 384w,/static/8e73a32ba44d53acc655b844c895e7e4/e5715/force_plot.png 768w,/static/8e73a32ba44d53acc655b844c895e7e4/75a80/force_plot.png 1134w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" class="Image-sc-n1k2df-0 cNyHKV gatsby-resp-image-image"/>
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption">Force Plot example. A force plot example.</figcaption>
  </figure><p>A force plot shows, for a single instance, which features contribute towards pushing the model to a certain value. As you can see above the the feature values shown in blue are reducing the prediction value while the feature vales shown in red are increasing the prediction. </p><h3 id="2-summary-plots" class="Primitives__H3-sc-1kfaxvk-2 eEpwqO"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#2-summary-plots">2. Summary Plots<!-- --> </a></h3><figure class="gatsby-resp-image-figure">
    <span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:768px">
      <a class="gatsby-resp-image-link" href="/static/300e77af12b4646537dc7dccc103751c/ae694/SHAP_summary-plots-example.png" target="_blank" rel="noopener" style="display:block">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:47.91666666666667%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAABs0lEQVQoz02RW28TMRCF99fzzC9AvCEEPCCkqpQClSJaUSLRtGoaJVEvKelm2Y3t9W099oyncsID82jNd86Z4yqlxMyJsnHBGuuGITjPSBTLu7UWAJiZKZP3YMxWmIjEOWNKlXVucLYx9Ob7ZnQwv/s8jbcNdz0KU0RTEkIMw8DKTs4eP769/vppvr6qWZhkh6rrOikVM5/OzeGL43g6Y+ZMmXrPuwmhJCoLU/Xq5fnk3cWfk4VvTQ6xCiFoXUwetvDt9ZhXfwuMlPRQ0JydddY6ZpYP4uD99PzDJRufANHHarvdCiGY2QQ6+7JMO8NM2fceiYwx6/XauQJTq68OZ79+F3UMyWtfSSn3cEx0MboXNlGh2SgfYwSApmn+wczjo8XyZFG6ANLSVNZapcrNoTU/R6uQ8t7ZuVgUYxRCeF/iRMDL8VotG2aGgBCwqut67wyr7ubHXcYCE2U3IOfc9/1ms7G2FAbMN9dt3+hdixjgPzgIdz95yj7uPjVrj+U2RK31PjYz385a8VRgD+SBqhgjIgKAlLJ9rHulhBDOeQ8p72a/4JxTStZ12zad1r0bAkR8BsvvNWZcqhUHAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img src="/static/300e77af12b4646537dc7dccc103751c/e5715/SHAP_summary-plots-example.png" alt="Summary Plots. Taken from research paper on interpreting machine learning models of biological age." title="Summary Plots. Taken from research paper on interpreting machine learning models of biological age." srcSet="/static/300e77af12b4646537dc7dccc103751c/8514f/SHAP_summary-plots-example.png 192w,/static/300e77af12b4646537dc7dccc103751c/804b2/SHAP_summary-plots-example.png 384w,/static/300e77af12b4646537dc7dccc103751c/e5715/SHAP_summary-plots-example.png 768w,/static/300e77af12b4646537dc7dccc103751c/ae694/SHAP_summary-plots-example.png 850w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" class="Image-sc-n1k2df-0 cNyHKV gatsby-resp-image-image"/>
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption">Summary Plots. Taken from research paper on interpreting machine learning models of biological age.</figcaption>
  </figure><p>We can combine multiple force plots together and then rotate it to have a summary across the entire dataset. Summary plots show many useful insights into all the features, each dot shows three characteristics: </p><div class="Spacing__ExtendingWrapper-sc-1sl48mq-0 cHsvLz"><ul class="List__UnorderedStyle-sc-1rx07kj-0 jTtpAZ"><li class="List__Item-sc-1rx07kj-2 dQWCGO">Vertical location is the feature it is representing.</li><li class="List__Item-sc-1rx07kj-2 dQWCGO">Color shows the magnitude of the feature value for that feature. </li><li class="List__Item-sc-1rx07kj-2 dQWCGO">Horizontal location is the effect of that value causing a higher or lower prediction. </li></ul></div><p>In the plots you can gain a strong intuition on how a decision was made by your black box model. Some features will generally have no input in the prediction until a certain feature value, whereas some features will have zero input and is ignored entirely by the model. </p><h3 id="3-shap-dependence-plots" class="Primitives__H3-sc-1kfaxvk-2 eEpwqO"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#3-shap-dependence-plots">3. SHAP Dependence Plots<!-- --> </a></h3><figure class="gatsby-resp-image-figure">
    <span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:496px">
      <a class="gatsby-resp-image-link" href="/static/51da19b92568b1855140a0668638e94c/bb630/SHAP_dependence_plots.png" target="_blank" rel="noopener" style="display:block">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:66.14583333333334%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACIklEQVQ4y2WTPYtTQRSG72+x9ydYWtjYWFlYiJWIWAVle7Gx0FIMYiFW2uiyyrKIKKRYQ4xxFyJsNNFsLhtzv3K/5n7MPDIzScxmD5zizJx55z3nPcdRSqEtyzLiOGYZa6ulgrUYFFIqk7N0cypKsvEUHTnLQyEEvu8jpTSxfgj2bruX8bBVMi0srFzcrNyPkZ3BaUDN0PM8A2jBYGcMlx785vz1LuduHNK494Xo4Bj8CNIMqhpECX4C30cWcFlMmqaWYVFZXmHM45vveXaxSftqk/2tt7xs7HL/zkdePDng66c/CFGRBjnSi6E3NDiOLlV7IQoDWC0++Nx4w4fn34B8Vbq24bRk56hm4NWUtbL5QYLs/iSpChxdqjuZECcJM/cE+aoFt5/y6NYu/QVIJa1A8pRA/P8oyohah7j+zDIcDUekSUKYZ3DhLh3nCu/2JlZpjaas2rrfcuHrKsdC0f4xYzZ1cZIkYT6fkyUpQTbneK/P1uXX7B9lq9Gxjxec1PrYWJZhAW23Ig09q7JWNs8F6Tyk70uuNf+aXpkRUWoD5OwcBrmiN7XjtlJZM40Cn3FYs91NUXKzX2dtmREIDWgjZ/mTBvRmM4pK8suXZ5jpKjbZWZEUfq7onGwArg93HCcEYUgURcZ1j/WcBkFg1jMMQ+P6PAoDYlEzmKZmh1Ylr69gXdcURUFZllRVZT5yXZc8zw1Tfa7z9F0uxGLfbQX/AGeZ3ejlOJhmAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img src="/static/51da19b92568b1855140a0668638e94c/bb630/SHAP_dependence_plots.png" alt="SHAP Dependence Plots. SHAP Dependence plot showing the affects of feature magnitude (age) on predicted values (marital status) and SHAP value." title="SHAP Dependence Plots. SHAP Dependence plot showing the affects of feature magnitude (age) on predicted values (marital status) and SHAP value." srcSet="/static/51da19b92568b1855140a0668638e94c/8514f/SHAP_dependence_plots.png 192w,/static/51da19b92568b1855140a0668638e94c/804b2/SHAP_dependence_plots.png 384w,/static/51da19b92568b1855140a0668638e94c/bb630/SHAP_dependence_plots.png 496w" sizes="(max-width: 496px) 100vw, 496px" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" class="Image-sc-n1k2df-0 cNyHKV gatsby-resp-image-image"/>
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption">SHAP Dependence Plots. SHAP Dependence plot showing the affects of feature magnitude (age) on predicted values (marital status) and SHAP value.</figcaption>
  </figure><p>The SHAP dependence plots are used to identify how a feature magnitude affects the predicted value. You can then observe the general pattern (or not) on how the feature affects prediction.</p><figure class="gatsby-resp-image-figure">
    <span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:517px">
      <a class="gatsby-resp-image-link" href="/static/6cd20bb0ad3cf6d619e70ccd842a8b6d/fa2f5/minimal_trend_shap_dependence_plot.png" target="_blank" rel="noopener" style="display:block">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:73.4375%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAACDElEQVQ4y4VU246bQAzl/3+mUqW+ROo+bLvKQ6Wqz+0qDaQFEsItDMNcbE7lARKyu20tjNFczhzPsYnGcYSYxOX7LVuvexVX+6L1pJhSCpvNBtvtFk+fn/D4+AlZlv0DLDwYhgHMjGiZlIHL5QLvPZIkwcPDR7z/8A5fv32BUt1ME2DihfMNOCnQJikI4wS4TBhjQERXtowBAIHhUA4x9NDJYGC07As7v/8GKnVLeWHYthc456+LiT0sa7BlnKoaqtPwhtB3Ft7dDqbnDJd9KmchEkZN0wQAYTgBzvkB8KOGrjvo1qE7KRS7MgA67WDsBNrFZ7RZCZaUu67Dfr8PYG3bgogDIMuLGIM2OORnqIHRNxrqVw3H010STYf2cQlbKWSnHJGoKoDCUNIWxp4RvK4HpD8btFpB+2FdQ8HHWaDyUCPdZ8iPOSJRdrfbBTBhK9KzZ5BnmN6ibUyQ59T/ALGdy2S+4xkwz3vUtUaep4gk1cPhEIAWlUcewZ4w9gbEk5I80q3u5qrwfgI8ZgrnQkrO3ass6ZOniaH1YQPziJfdtHaxfWEQ53UQ8lqHwiwwZL6Vg+PA9n/2XHrU9kXrWWvR930AlW/nXIieKFwHzVHGFzfGAuyR1A7JqQFGugeURdJ6U/lQiGmaoigKxHGMqqpwPB5nMHMVUbISMne9/Lc/jNY63O/i69Z8y/4Ap+mSmPAYe44AAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img src="/static/6cd20bb0ad3cf6d619e70ccd842a8b6d/fa2f5/minimal_trend_shap_dependence_plot.png" alt="Minimal Trend SHAP Dependence plot. SHAP Dependence plot showing a small trend between ball possession and goals scored. As you can see from the data, some teams record a 70% ball possession but fall short of scoring goals - which is what we would expect." title="Minimal Trend SHAP Dependence plot. SHAP Dependence plot showing a small trend between ball possession and goals scored. As you can see from the data, some teams record a 70% ball possession but fall short of scoring goals - which is what we would expect." srcSet="/static/6cd20bb0ad3cf6d619e70ccd842a8b6d/8514f/minimal_trend_shap_dependence_plot.png 192w,/static/6cd20bb0ad3cf6d619e70ccd842a8b6d/804b2/minimal_trend_shap_dependence_plot.png 384w,/static/6cd20bb0ad3cf6d619e70ccd842a8b6d/fa2f5/minimal_trend_shap_dependence_plot.png 517w" sizes="(max-width: 517px) 100vw, 517px" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" class="Image-sc-n1k2df-0 cNyHKV gatsby-resp-image-image"/>
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption">Minimal Trend SHAP Dependence plot. SHAP Dependence plot showing a small trend between ball possession and goals scored. As you can see from the data, some teams record a 70% ball possession but fall short of scoring goals - which is what we would expect.</figcaption>
  </figure><p>Conversely, if there was large standard deviation, with no apparent pattern, then we can assume that other features are interacting with this feature. Similarly, if a feature has arbitrary values then it would lead to arbitrary predictions. For example, a binary feature within the dataset of value 0 could make the feature under investigation more relevant but when the value is 1 makes the feature irrelevant. </p><p>If points follow a trend but are widely spread out (in both SHAP and feature magnitude) then we can assume the permutation importance is high because the prediction is sensitive to magnitude. However, a few outliers can ruin this assumption. It is worth producing Force plots for those points to understand why they do not follow the trend.</p><h2 id="local-interpretable-model-agnostic-explanations-lime" class="Primitives__H2-sc-1kfaxvk-1 hTdBcY"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#local-interpretable-model-agnostic-explanations-lime">Local Interpretable Model-Agnostic Explanations - LIME<!-- --> </a></h2><p>Lets reflect back on what we have learnt so far. Using <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">PI</code> and <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">PD</code> have their limitations, as discussed within the <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="./Interpreting-ML-Models">Part 1</a> blog. SHAP are subject to incorrect interpretation because the observations from multiple plots have to be used in order to make intuitions about the features. All these interpretation methodologies work really well with simple models but can be difficult to use, and interpret, when using it on complex models. These methods depend highly on model inference time and could take a lot of computational resources. This is where LIME (Local Interpretable Model-Agnostic Explanations) comes in. </p><p>LIME is a simple method that provides human-understandable model interpretation. It produces a local linear interpretable machine learning model which results in a reduced computational complexity. LIME is able to explain any complex model&#x27;s prediction and allow logical intuitions about the features.</p><figure class="gatsby-resp-image-figure">
    <span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:768px">
      <a class="gatsby-resp-image-link" href="/static/66a9ab9761fa21e8795da8afd46f0063/e8950/LIME_titanic_example.png" target="_blank" rel="noopener" style="display:block">
    <span class="gatsby-resp-image-background-image" style="padding-bottom:19.270833333333332%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsTAAALEwEAmpwYAAAArUlEQVQI112MOxIBURREZwsWY2k2gUgiUOSqLEEJlCqfgFiA8iuGwTXPfe8a824zEp8TdHUHp4PDOT4ZIYqjcxTzTUQkSZy14pz842ySsgenELmLSEBE/V53s14B8KoAos0iOuyy9o16AG4xpk4tHrY0cQACVb1u54YuCqQZj+VsGoZ7Zvsj+0eW7TIKORTzMMdM/lyrMrMx5kKkCu/9j/uek9GgXik1G1XL/JKfatDhFDFYCGAAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img src="/static/66a9ab9761fa21e8795da8afd46f0063/e5715/LIME_titanic_example.png" alt="LIME Titanic Example. Example of LIME interpreting a XGM model on predicting whether a passenger survived the Titanic. The model has realised that sex is an important feature." title="LIME Titanic Example. Example of LIME interpreting a XGM model on predicting whether a passenger survived the Titanic. The model has realised that sex is an important feature." srcSet="/static/66a9ab9761fa21e8795da8afd46f0063/8514f/LIME_titanic_example.png 192w,/static/66a9ab9761fa21e8795da8afd46f0063/804b2/LIME_titanic_example.png 384w,/static/66a9ab9761fa21e8795da8afd46f0063/e5715/LIME_titanic_example.png 768w,/static/66a9ab9761fa21e8795da8afd46f0063/4ad3a/LIME_titanic_example.png 1152w,/static/66a9ab9761fa21e8795da8afd46f0063/71c1d/LIME_titanic_example.png 1536w,/static/66a9ab9761fa21e8795da8afd46f0063/e8950/LIME_titanic_example.png 2000w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" class="Image-sc-n1k2df-0 cNyHKV gatsby-resp-image-image"/>
  </a>
    </span>
    <figcaption class="gatsby-resp-image-figcaption">LIME Titanic Example. Example of LIME interpreting a XGM model on predicting whether a passenger survived the Titanic. The model has realised that sex is an important feature.</figcaption>
  </figure><p>The <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://github.com/marcotcr/lime">`lime&#x27;</a> library was created by the originators of LIME. It has a simple API that allows us to gain explanations about the model no matter how complex. You can visualize the output of the <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">Explainer</code> objects to understand how each of the features influences the prediction - the <code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">Explainer</code> object is within the <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.explanation"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">Explanation</code> module</a>.</p><br/><h2 id="python-libraries" class="Primitives__H2-sc-1kfaxvk-1 hTdBcY"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#python-libraries">Python Libraries<!-- --> </a></h2><p>Below are relevant links to Python libraries, and code snippets, that have been discussed throughout the 2 blog posts.</p><div class="Spacing__ExtendingWrapper-sc-1sl48mq-0 cHsvLz"><ul class="List__UnorderedStyle-sc-1rx07kj-0 jTtpAZ"><li class="List__Item-sc-1rx07kj-2 dQWCGO"><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://pdpbox.readthedocs.io/en/latest/"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">PDPbox</code></a> helps visualize the partial dependence plots.</li><li class="List__Item-sc-1rx07kj-2 dQWCGO"><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://eli5.readthedocs.io/en/latest/index.html"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">eli5</code></a> helps debug and explain machine learning models, and helps us visualize permutation importance.</li><li class="List__Item-sc-1rx07kj-2 dQWCGO"><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://shap.readthedocs.io/en/latest/index.html"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">shap</code></a> allows us to interpret models using SHAP values.</li><li class="List__Item-sc-1rx07kj-2 dQWCGO"><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://github.com/marcotcr/lime"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">lime</code></a> allows us to use local explanations (LIME) to interpret models.</li></ul></div><h4 class="Primitives__H4-sc-1kfaxvk-3 fNseVF"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">pdpbox</code></h4><p><strong>Calculate and show partial dependence plot:</strong></p><div class="gatsby-highlight" data-language="py"><pre class="Code__Pre-sc-1hiidew-0 jhqbwH language-py"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-py" tabindex="0"><span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> pdpbox <span class="token keyword">import</span> pdp<span class="token punctuation">,</span> get_dataset<span class="token punctuation">,</span> info_plots

<span class="token comment"># Create the data that we will plot</span>
pdp_goals <span class="token operator">=</span> pdp<span class="token punctuation">.</span>pdp_isolate<span class="token punctuation">(</span>model<span class="token operator">=</span>my_model<span class="token punctuation">,</span> dataset<span class="token operator">=</span>X<span class="token punctuation">,</span> model_features<span class="token operator">=</span>feature_names<span class="token punctuation">,</span> feature<span class="token operator">=</span><span class="token string">&#x27;Goal Scored&#x27;</span><span class="token punctuation">)</span>

<span class="token comment"># plot it</span>
pdp<span class="token punctuation">.</span>pdp_plot<span class="token punctuation">(</span>pdp_goals<span class="token punctuation">,</span> <span class="token string">&#x27;Goal Scored&#x27;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div><h4 class="Primitives__H4-sc-1kfaxvk-3 fNseVF"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">eli5</code></h4><p><strong>Calculate and show permutation importance:</strong></p><div class="gatsby-highlight" data-language="py"><pre class="Code__Pre-sc-1hiidew-0 jhqbwH language-py"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-py" tabindex="0"><span class="token keyword">import</span> eli5
<span class="token keyword">from</span> eli5<span class="token punctuation">.</span>sklearn <span class="token keyword">import</span> PermutationImportance

perm <span class="token operator">=</span> PermutationImportance<span class="token punctuation">(</span>my_model<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
eli5<span class="token punctuation">.</span>show_weights<span class="token punctuation">(</span>perm<span class="token punctuation">,</span> feature_names <span class="token operator">=</span> X<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div><h4 class="Primitives__H4-sc-1kfaxvk-3 fNseVF"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">shap</code></h4><p><strong>Calculate and show SHAP Values for One Prediction (i.e Force plot):</strong></p><div class="gatsby-highlight" data-language="py"><pre class="Code__Pre-sc-1hiidew-0 jhqbwH language-py"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-py" tabindex="0"><span class="token keyword">import</span> shap  <span class="token comment"># package used to calculate Shap values</span>

<span class="token comment"># use 1 row of data here. Could use multiple rows if desired</span>
data_for_prediction <span class="token operator">=</span> X<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  

<span class="token comment"># Create object that can calculate shap values</span>
explainer <span class="token operator">=</span> shap<span class="token punctuation">.</span>TreeExplainer<span class="token punctuation">(</span>my_model<span class="token punctuation">)</span>
shap_values <span class="token operator">=</span> explainer<span class="token punctuation">.</span>shap_values<span class="token punctuation">(</span>data_for_prediction<span class="token punctuation">)</span>
shap<span class="token punctuation">.</span>initjs<span class="token punctuation">(</span><span class="token punctuation">)</span>
shap<span class="token punctuation">.</span>force_plot<span class="token punctuation">(</span>explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data_for_prediction<span class="token punctuation">)</span></code></pre></div><h4 class="Primitives__H4-sc-1kfaxvk-3 fNseVF"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-text" tabindex="0">lime</code></h4><p><strong>Calculate and show feature importance plot using LIME:</strong></p><div class="gatsby-highlight" data-language="py"><pre class="Code__Pre-sc-1hiidew-0 jhqbwH language-py"><code class="Code__StyledCode-sc-1hiidew-1 eUIYgH language-py" tabindex="0"><span class="token keyword">from</span> lime<span class="token punctuation">.</span>lime_text <span class="token keyword">import</span> LimeTextExplainer <span class="token comment"># import Explainer object</span>
explainer <span class="token operator">=</span> LimeTextExplainer<span class="token punctuation">(</span>class_names<span class="token operator">=</span>class_names<span class="token punctuation">)</span>

<span class="token comment"># create explainer object with single instance and a classifier function </span>
exp <span class="token operator">=</span> explainer<span class="token punctuation">.</span>explain_instance<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> pipeline<span class="token punctuation">.</span>predict_proba<span class="token punctuation">,</span> num_features<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span> 

<span class="token comment"># note: you should check how this local linear model compares</span>
<span class="token comment"># to your original model.</span>
<span class="token comment"># If the linear model is not representative of original model</span>
<span class="token comment"># for that region then it is not wise to use that linear </span>
<span class="token comment"># model to make conclusions about features.</span>

exp<span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># list of weighted features</span>
exp<span class="token punctuation">.</span>as_pyplot_figure<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># explanations return as a plot</span></code></pre></div><br/><h3 id="when-to-use-each" class="Primitives__H3-sc-1kfaxvk-2 eEpwqO"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#when-to-use-each">When to use each?<!-- --> </a></h3><p>Use <strong>permutation importance</strong> if you require a <strong>succinct model summary</strong>. Summarizing importance of all features in a global sense. </p><p>Use <strong>partial plot</strong> to understand <strong>individual features or relationships</strong> between features (i.e. using 2D partial dependence plots). Summarizing the importance of a single feature and its affect on the prediction in a global sense.</p><p>Use <strong>SHAP</strong> when you need to show the <strong>impact of each feature for a given row</strong>. If you require a global sense of a feature you can also use this too. </p><p>Use <strong>LIME</strong> when computational load is large for the above methods or if the outputs are ambiguous. This will allow you to understand your model from local points within you dataset.</p><p>Shapley values are the only method that provides contrastive explanations, where it has the potential to compare predictions to a subset of data, or a single data point. Using SHAP provides a consistent approach for both global and local explanations. Although, it can be easily misinterpreted. Meanwhile, methods like LIME are very easy to interpret. However, the premise that there is a local linear relationship might not always be true.</p><br/><h2 id="conclusion" class="Primitives__H2-sc-1kfaxvk-1 hTdBcY"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#conclusion">Conclusion<!-- --> </a></h2><p>Many methods can help us identify which features to focus on and then measure individual feature importance. However, interpreting these values are crucial for data scientists to avoid introducing biases into the prediction. SHAP is widely considered the optimal solution due to its Game Theory approach, however, all interpretation methods should be explored before being confirmed by a domain expert. SHAP has the potential to be misinterpreted and can hide biases. </p><p>Being able to use machine learning to predict the probability of a patient having cancer is a great asset to have for any health care professional. However, informing a patient, “you have a high probability of being diagnosed cancer” is not enough. Interpreting a machine learning model&#x27;s prediction can break down which features a patient should focus on in order to reduce their risk.</p><p>Model interpretation is not going away. Law makers will demand data scientists to interpret their models and these tools are just the start of an expanding specialism within data science. Personally, I am excited by tools like LIME, that are trying solve the limitations of its predecessors while providing even more insight about our machine learning models.</p><br/><h4 id="further-reading" class="Primitives__H4-sc-1kfaxvk-3 fNseVF"><a class="styles__HeadingLink-sc-1478t26-4 gyiRkg" href="/interpreting-ml-models-part-2#further-reading">Further reading:<!-- --> </a></h4><div class="Spacing__ExtendingWrapper-sc-1sl48mq-0 cHsvLz"><ul class="List__UnorderedStyle-sc-1rx07kj-0 jTtpAZ"><li class="List__Item-sc-1rx07kj-2 dQWCGO">Things to avoid when interpreting models - highly recommend reading <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://arxiv.org/pdf/2007.04131.pdf">this paper by Standford</a></li><li class="List__Item-sc-1rx07kj-2 dQWCGO"><a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning Book</a> by Christoph Molnar</li><li class="List__Item-sc-1rx07kj-2 dQWCGO">PyData Talk on <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://www.youtube.com/watch?v=C80SQe16Rao">Interpreting models with LIME and SHAPE</a></li><li class="List__Item-sc-1rx07kj-2 dQWCGO">PyData Talk on <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://www.youtube.com/watch?v=0yXtdkIL3Xk">SHAP Values</a></li><li class="List__Item-sc-1rx07kj-2 dQWCGO">SHAP Dependence plots <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://slundberg.github.io/shap/notebooks/plots/dependence_plot.html">Notebook</a></li><li class="List__Item-sc-1rx07kj-2 dQWCGO">A good example of a <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://www.researchgate.net/publication/330144045_An_interpretable_machine_learning_model_of_biological_age">researchgate paper</a> interpreting SHAP values to provide conclusions on Biological age. </li></ul></div></article><p class="Primitives__Body-sc-1kfaxvk-6 eKNIHW"><br/><i>If you are interested in more data science topics then check out my other blogs <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="./">here</a>.</i></p><section aria-label="Share on social media" class="styles__Wrapper-sc-wtfdzw-0 dLLVsH"><div class="styles__LinkWrapper-sc-wtfdzw-1 jcfxca"><h3 class="Primitives__H3-sc-1kfaxvk-2 styles__Label-sc-wtfdzw-2 eEpwqO klfMUO">SHARE</h3><div class="styles__LinkGrid-sc-wtfdzw-3 bdXlSx"><button aria-label="facebook" class="react-share__ShareButton" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 24 24" height="40" width="40" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M12.001 2.002c-5.522 0-9.999 4.477-9.999 9.999 0 4.99 3.656 9.126 8.437 9.879v-6.988h-2.54v-2.891h2.54V9.798c0-2.508 1.493-3.891 3.776-3.891 1.094 0 2.24.195 2.24.195v2.459h-1.264c-1.24 0-1.628.772-1.628 1.563v1.875h2.771l-.443 2.891h-2.328v6.988C18.344 21.129 22 16.992 22 12.001c0-5.522-4.477-9.999-9.999-9.999z"></path></svg></button><button aria-label="twitter" class="react-share__ShareButton" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 24 24" height="40" width="40" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M19.633 7.997c.013.175.013.349.013.523 0 5.325-4.053 11.461-11.46 11.461-2.282 0-4.402-.661-6.186-1.809.324.037.636.05.973.05a8.07 8.07 0 0 0 5.001-1.721 4.036 4.036 0 0 1-3.767-2.793c.249.037.499.062.761.062.361 0 .724-.05 1.061-.137a4.027 4.027 0 0 1-3.23-3.953v-.05c.537.299 1.16.486 1.82.511a4.022 4.022 0 0 1-1.796-3.354c0-.748.199-1.434.548-2.032a11.457 11.457 0 0 0 8.306 4.215c-.062-.3-.1-.611-.1-.923a4.026 4.026 0 0 1 4.028-4.028c1.16 0 2.207.486 2.943 1.272a7.957 7.957 0 0 0 2.556-.973 4.02 4.02 0 0 1-1.771 2.22 8.073 8.073 0 0 0 2.319-.624 8.645 8.645 0 0 1-2.019 2.083z"></path></svg></button><button aria-label="reddit" class="react-share__ShareButton" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 24 24" height="40" width="40" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><circle cx="9.67" cy="13" r="1.001"></circle><path d="M14.09 15.391A3.28 3.28 0 0 1 12 16a3.271 3.271 0 0 1-2.081-.63.27.27 0 0 0-.379.38c.71.535 1.582.809 2.471.77a3.811 3.811 0 0 0 2.469-.77v.04a.284.284 0 0 0 .006-.396.28.28 0 0 0-.396-.003zm.209-3.351a1 1 0 0 0 0 2l-.008.039c.016.002.033 0 .051 0a1 1 0 0 0 .958-1.038 1 1 0 0 0-1.001-1.001z"></path><path d="M12 2C6.479 2 2 6.477 2 12c0 5.521 4.479 10 10 10s10-4.479 10-10c0-5.523-4.479-10-10-10zm5.859 11.33c.012.146.012.293 0 .439 0 2.24-2.609 4.062-5.83 4.062s-5.83-1.82-5.83-4.062a2.681 2.681 0 0 1 0-.439 1.46 1.46 0 0 1-.455-2.327 1.458 1.458 0 0 1 2.063-.063 7.145 7.145 0 0 1 3.899-1.23l.743-3.47v-.004A.313.313 0 0 1 12.82 6l2.449.49a1.001 1.001 0 1 1-.131.61L13 6.65l-.649 3.12a7.123 7.123 0 0 1 3.85 1.23 1.46 1.46 0 0 1 2.469 1c.01.563-.307 1.08-.811 1.33z"></path></svg></button><button aria-label="linkedin" class="react-share__ShareButton" style="background-color:transparent;border:none;padding:0;font:inherit;color:inherit;cursor:pointer"><svg viewBox="0 0 24 24" height="40" width="40" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M20 3H4a1 1 0 0 0-1 1v16a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V4a1 1 0 0 0-1-1zM8.339 18.337H5.667v-8.59h2.672v8.59zM7.003 8.574a1.548 1.548 0 1 1 0-3.096 1.548 1.548 0 0 1 0 3.096zm11.335 9.763h-2.669V14.16c0-.996-.018-2.277-1.388-2.277-1.39 0-1.601 1.086-1.601 2.207v4.248h-2.667v-8.59h2.56v1.174h.037c.355-.675 1.227-1.387 2.524-1.387 2.704 0 3.203 1.778 3.203 4.092v4.71z"></path></svg></button><svg viewBox="0 0 24 24" height="40" width="40" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt styles__LinkButton-sc-wtfdzw-4 buJfop"><path d="M8.465 11.293c1.133-1.133 3.109-1.133 4.242 0l.707.707 1.414-1.414-.707-.707c-.943-.944-2.199-1.465-3.535-1.465s-2.592.521-3.535 1.465L4.929 12a5.008 5.008 0 0 0 0 7.071 4.983 4.983 0 0 0 3.535 1.462A4.982 4.982 0 0 0 12 19.071l.707-.707-1.414-1.414-.707.707a3.007 3.007 0 0 1-4.243 0 3.005 3.005 0 0 1 0-4.243l2.122-2.121z"></path><path d="m12 4.929-.707.707 1.414 1.414.707-.707a3.007 3.007 0 0 1 4.243 0 3.005 3.005 0 0 1 0 4.243l-2.122 2.121c-1.133 1.133-3.109 1.133-4.242 0L10.586 12l-1.414 1.414.707.707c.943.944 2.199 1.465 3.535 1.465s2.592-.521 3.535-1.465L19.071 12a5.008 5.008 0 0 0 0-7.071 5.006 5.006 0 0 0-7.071 0z"></path></svg></div></div><hr class="Separator-sc-vmi8al-0 bIVzKL"/></section></main><aside aria-label="About the author" class="styles__Wrapper-sc-1j7bgew-0 cINefJ"><div class="styles__Main-sc-1j7bgew-1 fMFOTK"><img src="https://avatars.githubusercontent.com/u/62998319?v=4" alt="Ashish Thanki" class="styles__Avatar-sc-1j7bgew-4 dMfpcP"/><div class="styles__Info-sc-1j7bgew-2 fKlCeM"><h3 class="Primitives__H3-sc-1kfaxvk-2 styles__AuthorName-sc-1j7bgew-6 eEpwqO ktJMSx">Ashish Thanki</h3><div class="styles__AboutText-sc-1j7bgew-7 szQTJ"><p class="Primitives__Body-sc-1kfaxvk-6 eKNIHW">A self taught data scientist, tech enthusiast, blogger and sports fan!</p></div></div></div><div class="styles__Contact-sc-1j7bgew-3 kVGYMk"><h3 class="Primitives__H3-sc-1kfaxvk-2 styles__ShareLabel-sc-1j7bgew-5 eEpwqO fcQYzl">Find me on</h3><div class="UserLinks__LinkGrid-sc-apim1l-0 cUfcIF styles__TightUserLinks-sc-1j7bgew-8 kVEIfd"><a class="styles__IconLink-sc-1478t26-3 gbJBje" href="https://twitter.com/Ashish__thanki" aria-label="Twitter Profile"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M19.633 7.997c.013.175.013.349.013.523 0 5.325-4.053 11.461-11.46 11.461-2.282 0-4.402-.661-6.186-1.809.324.037.636.05.973.05a8.07 8.07 0 0 0 5.001-1.721 4.036 4.036 0 0 1-3.767-2.793c.249.037.499.062.761.062.361 0 .724-.05 1.061-.137a4.027 4.027 0 0 1-3.23-3.953v-.05c.537.299 1.16.486 1.82.511a4.022 4.022 0 0 1-1.796-3.354c0-.748.199-1.434.548-2.032a11.457 11.457 0 0 0 8.306 4.215c-.062-.3-.1-.611-.1-.923a4.026 4.026 0 0 1 4.028-4.028c1.16 0 2.207.486 2.943 1.272a7.957 7.957 0 0 0 2.556-.973 4.02 4.02 0 0 1-1.771 2.22 8.073 8.073 0 0 0 2.319-.624 8.645 8.645 0 0 1-2.019 2.083z"></path></svg></a> <a class="styles__IconLink-sc-1478t26-3 gbJBje" href="https://github.com/ashishthanki" aria-label="GitHub Profile"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path fill-rule="evenodd" d="M12.026 2c-5.509 0-9.974 4.465-9.974 9.974 0 4.406 2.857 8.145 6.821 9.465.499.09.679-.217.679-.481 0-.237-.008-.865-.011-1.696-2.775.602-3.361-1.338-3.361-1.338-.452-1.152-1.107-1.459-1.107-1.459-.905-.619.069-.605.069-.605 1.002.07 1.527 1.028 1.527 1.028.89 1.524 2.336 1.084 2.902.829.091-.645.351-1.085.635-1.334-2.214-.251-4.542-1.107-4.542-4.93 0-1.087.389-1.979 1.024-2.675-.101-.253-.446-1.268.099-2.64 0 0 .837-.269 2.742 1.021a9.582 9.582 0 0 1 2.496-.336 9.554 9.554 0 0 1 2.496.336c1.906-1.291 2.742-1.021 2.742-1.021.545 1.372.203 2.387.099 2.64.64.696 1.024 1.587 1.024 2.675 0 3.833-2.33 4.675-4.552 4.922.355.308.675.916.675 1.846 0 1.334-.012 2.41-.012 2.737 0 .267.178.577.687.479C19.146 20.115 22 16.379 22 11.974 22 6.465 17.535 2 12.026 2z" clip-rule="evenodd"></path></svg></a><a class="styles__IconLink-sc-1478t26-3 gbJBje" href="https://uk.linkedin.com/in/athanki" aria-label="LinkedIn Profile"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M20 3H4a1 1 0 0 0-1 1v16a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V4a1 1 0 0 0-1-1zM8.339 18.337H5.667v-8.59h2.672v8.59zM7.003 8.574a1.548 1.548 0 1 1 0-3.096 1.548 1.548 0 0 1 0 3.096zm11.335 9.763h-2.669V14.16c0-.996-.018-2.277-1.388-2.277-1.39 0-1.601 1.086-1.601 2.207v4.248h-2.667v-8.59h2.56v1.174h.037c.355-.675 1.227-1.387 2.524-1.387 2.704 0 3.203 1.778 3.203 4.092v4.71z"></path></svg></a> <a class="styles__IconLink-sc-1478t26-3 gbJBje" href="mailto:ashish_thanki@hotmail.com" aria-label="E-Mail"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M20 4H6c-1.103 0-2 .897-2 2v5h2V8l6.4 4.8a1.001 1.001 0 0 0 1.2 0L20 8v9h-8v2h8c1.103 0 2-.897 2-2V6c0-1.103-.897-2-2-2zm-7 6.75L6.666 6h12.668L13 10.75z"></path><path d="M2 12h7v2H2zm2 3h6v2H4zm3 3h4v2H7z"></path></svg></a></div></div><hr class="Separator-sc-vmi8al-0 styles__Separator-sc-1j7bgew-9 bIVzKL emthwx"/></aside><aside class="RelatedPosts__Wrapper-sc-1ga516s-0 hZSFY"><h2 class="Primitives__H2-sc-1kfaxvk-1 RelatedPosts__Label-sc-1ga516s-1 hTdBcY kudTDK">RELATED POSTS</h2><div class="LayoutWidthContainer-sc-obprvr-0 FeedListing__WidthLimitedGrid-sc-xfguai-1 fwyrVH hUCjhI"><div class="FeedListing__Wrapper-sc-xfguai-0 dOUrHM"><div class="styles__Wrapper-sc-ifqbpj-1 dIefSC"><a aria-current="page" class="styles__TransparentLink-sc-1478t26-1 jMACNl" aria-label="Interpreting ML Models Part 2" href="/interpreting-ml-models-part-2"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained styles__Cover-sc-ifqbpj-0 irueSx"><div style="max-width:920px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg height=&#x27;368&#x27; width=&#x27;920&#x27; xmlns=&#x27;http://www.w3.org/2000/svg&#x27; version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:transparent;position:absolute;top:0;left:0;bottom:0;right:0" decoding="async" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAGkhnAX/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAEDERMU/9oACAEBAAEFAnM2bUdDP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAABITH/2gAIAQEABj8CjRWYf//EABoQAAICAwAAAAAAAAAAAAAAAAABIVExYbH/2gAIAQEAAT8hzaQ7XSkq4P/aAAwDAQACAAMAAAAQDC//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEUH/2gAIAQMBAT8Q2I//xAAWEQEBAQAAAAAAAAAAAAAAAAABEQD/2gAIAQIBAT8QGl1d/8QAHBABAAICAwEAAAAAAAAAAAAAAQAhEZExUWGx/9oACAEBAAE/EDEe0jSbichdpTUAoMemXyf/2Q==" alt=""/><picture><source type="image/avif" data-srcset="/static/b57872d67fc00d945468ce891f38f187/ee20b/cover_6.avif 230w,/static/b57872d67fc00d945468ce891f38f187/5c720/cover_6.avif 460w,/static/b57872d67fc00d945468ce891f38f187/991c3/cover_6.avif 920w,/static/b57872d67fc00d945468ce891f38f187/b7eae/cover_6.avif 1840w" sizes="(min-width: 920px) 920px, 100vw"/><source type="image/webp" data-srcset="/static/b57872d67fc00d945468ce891f38f187/1d6f2/cover_6.webp 230w,/static/b57872d67fc00d945468ce891f38f187/f0b6f/cover_6.webp 460w,/static/b57872d67fc00d945468ce891f38f187/d54e9/cover_6.webp 920w,/static/b57872d67fc00d945468ce891f38f187/382d3/cover_6.webp 1840w" sizes="(min-width: 920px) 920px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 920px) 920px, 100vw" decoding="async" loading="lazy" data-src="/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg" data-srcset="/static/b57872d67fc00d945468ce891f38f187/2ab11/cover_6.jpg 230w,/static/b57872d67fc00d945468ce891f38f187/16c5c/cover_6.jpg 460w,/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg 920w,/static/b57872d67fc00d945468ce891f38f187/3f865/cover_6.jpg 1840w" alt="A view of mountains."/></picture><noscript><picture><source type="image/avif" srcSet="/static/b57872d67fc00d945468ce891f38f187/ee20b/cover_6.avif 230w,/static/b57872d67fc00d945468ce891f38f187/5c720/cover_6.avif 460w,/static/b57872d67fc00d945468ce891f38f187/991c3/cover_6.avif 920w,/static/b57872d67fc00d945468ce891f38f187/b7eae/cover_6.avif 1840w" sizes="(min-width: 920px) 920px, 100vw"/><source type="image/webp" srcSet="/static/b57872d67fc00d945468ce891f38f187/1d6f2/cover_6.webp 230w,/static/b57872d67fc00d945468ce891f38f187/f0b6f/cover_6.webp 460w,/static/b57872d67fc00d945468ce891f38f187/d54e9/cover_6.webp 920w,/static/b57872d67fc00d945468ce891f38f187/382d3/cover_6.webp 1840w" sizes="(min-width: 920px) 920px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 920px) 920px, 100vw" decoding="async" loading="lazy" src="/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg" srcSet="/static/b57872d67fc00d945468ce891f38f187/2ab11/cover_6.jpg 230w,/static/b57872d67fc00d945468ce891f38f187/16c5c/cover_6.jpg 460w,/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg 920w,/static/b57872d67fc00d945468ce891f38f187/3f865/cover_6.jpg 1840w" alt="A view of mountains."/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></a><div class="styles__Details-sc-ifqbpj-5 GlBhT"><div class="styles__Meta-sc-ifqbpj-4 izGZyP"><div class="styles__Header-sc-ifqbpj-2 eSQGhX"><div class="styles__Wrapper-sc-evad3c-5 dofHQH"><div class="styles__InfoGrid-sc-evad3c-3 duPBEk"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ styles__CategoryLink-sc-evad3c-1 eyoDpl" href="/category/Interpretability">Interpretability</a><p class="Primitives__Caption-sc-1kfaxvk-7 styles__Caption-sc-evad3c-2 ksrFqo kToWai"> ⋅ Sep 26, 2021 ⋅ 7 min read</p></div><div class="styles__TagGrid-sc-evad3c-4 eWUSCD"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ styles__TagLink-sc-evad3c-0 coRloj" href="/tag/Machine Learning">Machine Learning</a></div></div><a aria-current="page" class="styles__TransparentLink-sc-1478t26-1 jMACNl" href="/interpreting-ml-models-part-2"><h2 class="Primitives__H3-sc-1kfaxvk-2 eEpwqO">Interpreting ML Models Part 2</h2></a></div><a aria-current="page" class="styles__TransparentLink-sc-1478t26-1 jMACNl" aria-label="Interpreting ML Models Part 2" href="/interpreting-ml-models-part-2"><p class="Primitives__Body-sc-1kfaxvk-6 styles__Excerpt-sc-ifqbpj-3 eKNIHW gNCZZM">Introduction Explaining features and interpreting your models has taken a sharp rise in Europe. Partly because of new laws and regulatory…</p></a></div></div></div><div class="styles__Wrapper-sc-ifqbpj-1 dIefSC"><a class="styles__TransparentLink-sc-1478t26-1 jMACNl" aria-label="Interpreting ML Models" href="/interpreting-ml-models"><div data-gatsby-image-wrapper="" class="gatsby-image-wrapper gatsby-image-wrapper-constrained styles__Cover-sc-ifqbpj-0 irueSx"><div style="max-width:920px;display:block"><img alt="" role="presentation" aria-hidden="true" src="data:image/svg+xml;charset=utf-8,%3Csvg height=&#x27;368&#x27; width=&#x27;920&#x27; xmlns=&#x27;http://www.w3.org/2000/svg&#x27; version=&#x27;1.1&#x27;%3E%3C/svg%3E" style="max-width:100%;display:block;position:static"/></div><img aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:transparent;position:absolute;top:0;left:0;bottom:0;right:0" decoding="async" src="data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAGkhnAX/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAEDERMU/9oACAEBAAEFAnM2bUdDP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAABITH/2gAIAQEABj8CjRWYf//EABoQAAICAwAAAAAAAAAAAAAAAAABIVExYbH/2gAIAQEAAT8hzaQ7XSkq4P/aAAwDAQACAAMAAAAQDC//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEUH/2gAIAQMBAT8Q2I//xAAWEQEBAQAAAAAAAAAAAAAAAAABEQD/2gAIAQIBAT8QGl1d/8QAHBABAAICAwEAAAAAAAAAAAAAAQAhEZExUWGx/9oACAEBAAE/EDEe0jSbichdpTUAoMemXyf/2Q==" alt=""/><picture><source type="image/avif" data-srcset="/static/b57872d67fc00d945468ce891f38f187/ee20b/cover_6.avif 230w,/static/b57872d67fc00d945468ce891f38f187/5c720/cover_6.avif 460w,/static/b57872d67fc00d945468ce891f38f187/991c3/cover_6.avif 920w,/static/b57872d67fc00d945468ce891f38f187/b7eae/cover_6.avif 1840w" sizes="(min-width: 920px) 920px, 100vw"/><source type="image/webp" data-srcset="/static/b57872d67fc00d945468ce891f38f187/1d6f2/cover_6.webp 230w,/static/b57872d67fc00d945468ce891f38f187/f0b6f/cover_6.webp 460w,/static/b57872d67fc00d945468ce891f38f187/d54e9/cover_6.webp 920w,/static/b57872d67fc00d945468ce891f38f187/382d3/cover_6.webp 1840w" sizes="(min-width: 920px) 920px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 920px) 920px, 100vw" decoding="async" loading="lazy" data-src="/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg" data-srcset="/static/b57872d67fc00d945468ce891f38f187/2ab11/cover_6.jpg 230w,/static/b57872d67fc00d945468ce891f38f187/16c5c/cover_6.jpg 460w,/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg 920w,/static/b57872d67fc00d945468ce891f38f187/3f865/cover_6.jpg 1840w" alt="A view of mountains"/></picture><noscript><picture><source type="image/avif" srcSet="/static/b57872d67fc00d945468ce891f38f187/ee20b/cover_6.avif 230w,/static/b57872d67fc00d945468ce891f38f187/5c720/cover_6.avif 460w,/static/b57872d67fc00d945468ce891f38f187/991c3/cover_6.avif 920w,/static/b57872d67fc00d945468ce891f38f187/b7eae/cover_6.avif 1840w" sizes="(min-width: 920px) 920px, 100vw"/><source type="image/webp" srcSet="/static/b57872d67fc00d945468ce891f38f187/1d6f2/cover_6.webp 230w,/static/b57872d67fc00d945468ce891f38f187/f0b6f/cover_6.webp 460w,/static/b57872d67fc00d945468ce891f38f187/d54e9/cover_6.webp 920w,/static/b57872d67fc00d945468ce891f38f187/382d3/cover_6.webp 1840w" sizes="(min-width: 920px) 920px, 100vw"/><img data-gatsby-image-ssr="" data-main-image="" style="opacity:0" sizes="(min-width: 920px) 920px, 100vw" decoding="async" loading="lazy" src="/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg" srcSet="/static/b57872d67fc00d945468ce891f38f187/2ab11/cover_6.jpg 230w,/static/b57872d67fc00d945468ce891f38f187/16c5c/cover_6.jpg 460w,/static/b57872d67fc00d945468ce891f38f187/d43de/cover_6.jpg 920w,/static/b57872d67fc00d945468ce891f38f187/3f865/cover_6.jpg 1840w" alt="A view of mountains"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1)}}</script></div></a><div class="styles__Details-sc-ifqbpj-5 GlBhT"><div class="styles__Meta-sc-ifqbpj-4 izGZyP"><div class="styles__Header-sc-ifqbpj-2 eSQGhX"><div class="styles__Wrapper-sc-evad3c-5 dofHQH"><div class="styles__InfoGrid-sc-evad3c-3 duPBEk"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ styles__CategoryLink-sc-evad3c-1 eyoDpl" href="/category/Interpretability">Interpretability</a><p class="Primitives__Caption-sc-1kfaxvk-7 styles__Caption-sc-evad3c-2 ksrFqo kToWai"> ⋅ Jul 2, 2021 ⋅ 5 min read</p></div><div class="styles__TagGrid-sc-evad3c-4 eWUSCD"><a class="styles__PrimaryLink-sc-1478t26-2 glUXfQ styles__TagLink-sc-evad3c-0 coRloj" href="/tag/Machine Learning">Machine Learning</a></div></div><a class="styles__TransparentLink-sc-1478t26-1 jMACNl" href="/interpreting-ml-models"><h2 class="Primitives__H3-sc-1kfaxvk-2 eEpwqO">Interpreting ML Models</h2></a></div><a class="styles__TransparentLink-sc-1478t26-1 jMACNl" aria-label="Interpreting ML Models" href="/interpreting-ml-models"><p class="Primitives__Body-sc-1kfaxvk-6 styles__Excerpt-sc-ifqbpj-3 eKNIHW gNCZZM">Introduction Explaining features and interpreting your models has taken a sharp rise in Europe. Partly because of new laws and regulatory…</p></a></div></div></div></div></div></aside></div><footer class="styles__Wrapper-sc-1gphmby-0 dA-DcVw"><section class="styles__LinkGrid-sc-1gphmby-1 bKLfTS"><h3 class="Primitives__H3-sc-1kfaxvk-2 eEpwqO">LINKS</h3><div class="UserLinks__LinkGrid-sc-apim1l-0 cUfcIF"><a class="styles__IconLink-sc-1478t26-3 gbJBje" href="https://twitter.com/Ashish__thanki" aria-label="Twitter Profile"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M19.633 7.997c.013.175.013.349.013.523 0 5.325-4.053 11.461-11.46 11.461-2.282 0-4.402-.661-6.186-1.809.324.037.636.05.973.05a8.07 8.07 0 0 0 5.001-1.721 4.036 4.036 0 0 1-3.767-2.793c.249.037.499.062.761.062.361 0 .724-.05 1.061-.137a4.027 4.027 0 0 1-3.23-3.953v-.05c.537.299 1.16.486 1.82.511a4.022 4.022 0 0 1-1.796-3.354c0-.748.199-1.434.548-2.032a11.457 11.457 0 0 0 8.306 4.215c-.062-.3-.1-.611-.1-.923a4.026 4.026 0 0 1 4.028-4.028c1.16 0 2.207.486 2.943 1.272a7.957 7.957 0 0 0 2.556-.973 4.02 4.02 0 0 1-1.771 2.22 8.073 8.073 0 0 0 2.319-.624 8.645 8.645 0 0 1-2.019 2.083z"></path></svg></a> <a class="styles__IconLink-sc-1478t26-3 gbJBje" href="https://github.com/ashishthanki" aria-label="GitHub Profile"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path fill-rule="evenodd" d="M12.026 2c-5.509 0-9.974 4.465-9.974 9.974 0 4.406 2.857 8.145 6.821 9.465.499.09.679-.217.679-.481 0-.237-.008-.865-.011-1.696-2.775.602-3.361-1.338-3.361-1.338-.452-1.152-1.107-1.459-1.107-1.459-.905-.619.069-.605.069-.605 1.002.07 1.527 1.028 1.527 1.028.89 1.524 2.336 1.084 2.902.829.091-.645.351-1.085.635-1.334-2.214-.251-4.542-1.107-4.542-4.93 0-1.087.389-1.979 1.024-2.675-.101-.253-.446-1.268.099-2.64 0 0 .837-.269 2.742 1.021a9.582 9.582 0 0 1 2.496-.336 9.554 9.554 0 0 1 2.496.336c1.906-1.291 2.742-1.021 2.742-1.021.545 1.372.203 2.387.099 2.64.64.696 1.024 1.587 1.024 2.675 0 3.833-2.33 4.675-4.552 4.922.355.308.675.916.675 1.846 0 1.334-.012 2.41-.012 2.737 0 .267.178.577.687.479C19.146 20.115 22 16.379 22 11.974 22 6.465 17.535 2 12.026 2z" clip-rule="evenodd"></path></svg></a><a class="styles__IconLink-sc-1478t26-3 gbJBje" href="https://uk.linkedin.com/in/athanki" aria-label="LinkedIn Profile"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M20 3H4a1 1 0 0 0-1 1v16a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V4a1 1 0 0 0-1-1zM8.339 18.337H5.667v-8.59h2.672v8.59zM7.003 8.574a1.548 1.548 0 1 1 0-3.096 1.548 1.548 0 0 1 0 3.096zm11.335 9.763h-2.669V14.16c0-.996-.018-2.277-1.388-2.277-1.39 0-1.601 1.086-1.601 2.207v4.248h-2.667v-8.59h2.56v1.174h.037c.355-.675 1.227-1.387 2.524-1.387 2.704 0 3.203 1.778 3.203 4.092v4.71z"></path></svg></a> <a class="styles__IconLink-sc-1478t26-3 gbJBje" href="mailto:ashish_thanki@hotmail.com" aria-label="E-Mail"><svg viewBox="0 0 24 24" height="48" width="48" aria-hidden="true" focusable="false" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="StyledIconBase-ea9ulj-0 fHrGFt"><path d="M20 4H6c-1.103 0-2 .897-2 2v5h2V8l6.4 4.8a1.001 1.001 0 0 0 1.2 0L20 8v9h-8v2h8c1.103 0 2-.897 2-2V6c0-1.103-.897-2-2-2zm-7 6.75L6.666 6h12.668L13 10.75z"></path><path d="M2 12h7v2H2zm2 3h6v2H4zm3 3h4v2H7z"></path></svg></a></div></section><div class="styles__Info-sc-1gphmby-2 eOeOIj"><p class="Primitives__Caption-sc-1kfaxvk-7 ksrFqo"> <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="/">Posts</a> | <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="/about">About</a> | <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://twitter.com/ashish__thanki">Twitter</a> | <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://www.github.com/ashishthanki">GitHub</a> | <a class="styles__AnimatedLink-sc-1478t26-0 kInRwt" href="https://uk.linkedin.com/in/athanki">LinkedIn</a></p><p class="Primitives__Caption-sc-1kfaxvk-7 ksrFqo">© Copyright 2022 | Ashish Thanki</p></div></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LTSDW45Z4C"></script><script>
      
      
      if(true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){window.dataLayer && window.dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-LTSDW45Z4C', {"send_page_view":false});
      }
      </script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/interpreting-ml-models-part-2";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-1c86ca631959ce2f61f7.js"],"app":["/app-f22f5a19420f4ca20847.js"],"component---cache-caches-gatsby-plugin-offline-app-shell-js":["/component---cache-caches-gatsby-plugin-offline-app-shell-js-276bcbdeff3fbcc22391.js"],"component---src-pages-example-tsx":["/component---src-pages-example-tsx-6764ed195194415be83e.js"],"component---themes-advanced-src-templates-post-query-ts":["/component---themes-advanced-src-templates-post-query-ts-90b9d532d7784b7497f4.js"],"component---themes-amaranth-src-gatsby-theme-advanced-templates-feed-index-tsx":[],"component---themes-amaranth-src-pages-about-tsx":["/component---themes-amaranth-src-pages-about-tsx-ab17e39daf1e3a55d206.js"]};/*]]>*/</script><script src="/polyfill-1c86ca631959ce2f61f7.js" nomodule=""></script><script src="/component---themes-advanced-src-templates-post-query-ts-90b9d532d7784b7497f4.js" async=""></script><script src="/3a5981d123eec27129dd35f297abe92aafc96141-111e96cba930f7ce0d45.js" async=""></script><script src="/1d2d7d1d436f49e73dd3293234cd23312ebe1944-2e06c528b8e91ae27611.js" async=""></script><script src="/app-f22f5a19420f4ca20847.js" async=""></script><script src="/532a2f07-bee56c167ebe722e4032.js" async=""></script><script src="/framework-fd08d525545552f00d3a.js" async=""></script><script src="/webpack-runtime-f5df9ae31cf3fa65ae1f.js" async=""></script></body></html>